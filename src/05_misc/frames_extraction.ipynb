{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import shutil # Though not explicitly used in the final version, it's good for file ops\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "# import os # already imported\n",
    "\n",
    "# Suppress FutureWarning from sklearn.cluster.KMeans regarding n_init\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"sklearn.cluster._kmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- General Parameters ---\n",
    "# How many dishes to attempt to download for training and testing\n",
    "NUM_DISHES_TO_DOWNLOAD_TRAIN = 10000 # Reduced for quicker testing, set to 10000 for full run\n",
    "NUM_DISHES_TO_DOWNLOAD_TEST = 10   # Example for test set, not used in this script's main loop\n",
    "RANDOM_SAMPLE_FROM_SPLIT = True    # True to randomly sample from split files, False to take first N\n",
    "\n",
    "# --- Base Local Directory ---\n",
    "# Ensure this path is correct for your system\n",
    "# LOCAL_BASE_DIR = \"/users/eleves-b/2023/georgii.kuznetsov/CNN_nutrition/nutrition5k\"\n",
    "LOCAL_BASE_DIR = \"/Data/nutrition5k\"\n",
    "\n",
    "# --- Google Cloud Storage Bucket ---\n",
    "GSUTIL_BUCKET_BASE = \"gs://nutrition5k_dataset/nutrition5k_dataset/\"\n",
    "\n",
    "# --- Metadata and Split Files ---\n",
    "METADATA_DIR = os.path.join(LOCAL_BASE_DIR, \"metadata\")\n",
    "TRAIN_SPLIT_FILE_RGB = os.path.join(LOCAL_BASE_DIR, \"dish_ids/splits/rgb_train_ids.txt\")\n",
    "TEST_SPLIT_FILE_RGB = os.path.join(LOCAL_BASE_DIR, \"dish_ids/splits/rgb_test_ids.txt\") # For future use\n",
    "\n",
    "# --- Overhead Imagery (Realsense) ---\n",
    "# Remote subdirectory on GCS for overhead images\n",
    "IMAGERY_SUBDIR_REMOTE = \"imagery/realsense_overhead\"\n",
    "# Local subdirectory to store overhead images\n",
    "IMAGERY_SUBDIR_LOCAL = \"imagery/realsense_overhead\"\n",
    "IMAGERY_DIR_LOCAL_FULL = os.path.join(LOCAL_BASE_DIR, IMAGERY_SUBDIR_LOCAL)\n",
    "# Filenames of overhead images to download per dish\n",
    "FILENAME_ON_BUCKET = [\"depth_color.png\", \"depth_raw.png\", \"rgb.png\"]\n",
    "\n",
    "# --- Video Processing (Side Angles) ---\n",
    "# Remote subdirectory on GCS for videos\n",
    "VIDEO_SUBDIR_REMOTE = \"imagery/side_angles\"\n",
    "# Local subdirectory to store videos (temporarily) and extracted frames\n",
    "VIDEO_SUBDIR_LOCAL = \"imagery/side_angles\"\n",
    "VIDEO_DIR_LOCAL_FULL = os.path.join(LOCAL_BASE_DIR, VIDEO_SUBDIR_LOCAL)\n",
    "# Subdirectory within each dish's video folder to save extracted frames\n",
    "FRAMES_SUBDIR = \"extracted_frames\"\n",
    "# Filenames of videos to download and process per dish\n",
    "VIDEO_FILENAMES = [\"camera_A.h264\", \"camera_B.h264\", \"camera_C.h264\", \"camera_D.h264\"]\n",
    "\n",
    "# --- Frame Extraction Parameters ---\n",
    "NUM_FRAMES_PER_VIDEO = 5     # Number of diverse frames to extract per video\n",
    "SAMPLE_EVERY_NTH_FRAME = 1   # Sample every Nth frame from video for diversity analysis pool\n",
    "\n",
    "MAX_WORKERS = os.cpu_count() if os.cpu_count() else 4 # Number of parallel processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "os.makedirs(METADATA_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGERY_DIR_LOCAL_FULL, exist_ok=True) # For overhead images\n",
    "os.makedirs(VIDEO_DIR_LOCAL_FULL, exist_ok=True)   # For videos and their extracted frames\n",
    "os.makedirs(os.path.join(LOCAL_BASE_DIR, \"dish_ids\", \"splits\"), exist_ok=True) # For split files\n",
    "print(f\"Base local directory set to: {LOCAL_BASE_DIR}\")\n",
    "print(f\"Overhead imagery will be stored in: {IMAGERY_DIR_LOCAL_FULL}\")\n",
    "print(f\"Video frames will be stored in subdirectories under: {VIDEO_DIR_LOCAL_FULL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA # Assuming PCA might be used\n",
    "\n",
    "def extract_frame_features(frame): # This is the more robust version used by GMM\n",
    "    \"\"\"\n",
    "    Extract features from a frame for diversity analysis.\n",
    "    Using color histogram and basic texture features.\n",
    "    \"\"\"\n",
    "    small_frame = cv2.resize(frame, (64, 64))\n",
    "    \n",
    "    hsv = cv2.cvtColor(small_frame, cv2.COLOR_BGR2HSV)\n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [32], [0, 180])\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [32], [0, 256])\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [32], [0, 256])\n",
    "    \n",
    "    sum_h = np.sum(hist_h); hist_h = hist_h.flatten() / sum_h if sum_h > 0 else hist_h.flatten() * 0\n",
    "    sum_s = np.sum(hist_s); hist_s = hist_s.flatten() / sum_s if sum_s > 0 else hist_s.flatten() * 0\n",
    "    sum_v = np.sum(hist_v); hist_v = hist_v.flatten() / sum_v if sum_v > 0 else hist_v.flatten() * 0\n",
    "    \n",
    "    gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    edge_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    edge_hist_values = edge_magnitude.flatten()\n",
    "    valid_edge_values = edge_hist_values[edge_hist_values >= 0]\n",
    "    \n",
    "    if len(valid_edge_values) > 0:\n",
    "        hist_range_max = np.percentile(valid_edge_values, 99.9) + 1e-5\n",
    "        if hist_range_max <= 1e-5: hist_range_max = 256 # Fallback if percentile is 0 or very small\n",
    "        edge_hist, _ = np.histogram(valid_edge_values, bins=32, range=(0, hist_range_max))\n",
    "    else:\n",
    "        edge_hist = np.zeros(32)\n",
    "\n",
    "    sum_edge = np.sum(edge_hist)\n",
    "    edge_hist = edge_hist.flatten() / sum_edge if sum_edge > 0 else edge_hist.flatten() * 0\n",
    "        \n",
    "    features = np.concatenate([hist_h, hist_s, hist_v, edge_hist])\n",
    "    return features\n",
    "\n",
    "\n",
    "def select_diverse_frames_gmm(video_path, num_frames_to_select=5, sample_every_nth=5, max_gmm_components_eval=10):\n",
    "    \"\"\"\n",
    "    Select diverse frames from a video using GMM and BIC for model selection.\n",
    "    Returns: (selected_frames_list, selected_frame_indices_list, messages_list)\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        messages.append(f\"Error: Could not open video {video_path}\")\n",
    "        return [], [], messages\n",
    "    \n",
    "    frames_pool = []\n",
    "    features_pool = []\n",
    "    frame_indices_pool = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % sample_every_nth == 0:\n",
    "            try:\n",
    "                current_features = extract_frame_features(frame)\n",
    "                frames_pool.append(frame) # Add frame only if feature extraction succeeds\n",
    "                features_pool.append(current_features)\n",
    "                frame_indices_pool.append(frame_count)\n",
    "            except Exception as e:\n",
    "                messages.append(f\"Warning: Could not extract features for frame {frame_count} from {video_path}. Error: {e}\")\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "\n",
    "    messages.append(f'Sampled {len(frames_pool)} usable frames from video (total frames processed: {frame_count})')\n",
    "    \n",
    "    if not frames_pool:\n",
    "        messages.append(f\"Warning: No usable frames successfully sampled from {video_path}\")\n",
    "        return [], [], messages\n",
    "    \n",
    "    if len(frames_pool) <= num_frames_to_select:\n",
    "        messages.append(f\"Info: Sampled frames ({len(frames_pool)}) <= requested ({num_frames_to_select}). Returning all sampled frames.\")\n",
    "        return frames_pool, frame_indices_pool, messages\n",
    "\n",
    "    features_array = np.array(features_pool)\n",
    "    n_samples, n_features = features_array.shape\n",
    "    pca_applied = False\n",
    "\n",
    "    if n_samples <= 1:\n",
    "        messages.append(f\"Info: Only {n_samples} frame available post-sampling. Returning this frame.\")\n",
    "        return frames_pool[:n_samples], frame_indices_pool[:n_samples], messages\n",
    "\n",
    "    if n_features > 50 and n_samples > 50 :\n",
    "        pca_n_components = min(50, n_samples -1, n_features -1)\n",
    "        if pca_n_components > 1 : \n",
    "             pca = PCA(n_components=pca_n_components, random_state=42)\n",
    "             features_array = pca.fit_transform(features_array)\n",
    "             pca_applied = True\n",
    "    elif n_samples > 2 and n_features > 1 :\n",
    "        max_pca_components_small = min(n_samples - 1, n_features -1, 10)\n",
    "        if max_pca_components_small > 1:\n",
    "            pca = PCA(n_components=max_pca_components_small, random_state=42)\n",
    "            features_array = pca.fit_transform(features_array)\n",
    "            pca_applied = True\n",
    "    \n",
    "    if pca_applied:\n",
    "        n_samples, n_features = features_array.shape\n",
    "        messages.append(f\"Info: PCA applied. New feature dimensions: {n_features}\")\n",
    "\n",
    "    upper_bound_gmm_test = min(max_gmm_components_eval, n_samples)\n",
    "    if num_frames_to_select + 5 < upper_bound_gmm_test:\n",
    "        upper_bound_gmm_test = min(upper_bound_gmm_test, num_frames_to_select + 5)\n",
    "    \n",
    "    upper_bound_gmm_test = max(1, upper_bound_gmm_test) # Ensure at least 1\n",
    "    if upper_bound_gmm_test == 1 and n_samples > 1: upper_bound_gmm_test = 2\n",
    "\n",
    "    min_gmm_components_test = 1\n",
    "    n_components_range = range(min_gmm_components_test, upper_bound_gmm_test + 1)\n",
    "\n",
    "    if not list(n_components_range) or n_samples < min_gmm_components_test :\n",
    "         messages.append(f\"Warning: Not enough samples ({n_samples}) for GMM (Range: {list(n_components_range)}). Returning first {num_frames_to_select} frames from pool.\")\n",
    "         return frames_pool[:num_frames_to_select], frame_indices_pool[:num_frames_to_select], messages\n",
    "\n",
    "    bics = []\n",
    "    lowest_bic = np.infty\n",
    "    actual_n_components_for_gmm = 0\n",
    "    messages.append(f\"Info: Evaluating GMM components in range: {list(n_components_range)}\")\n",
    "\n",
    "    for n_comp in n_components_range:\n",
    "        if n_comp > n_samples or n_comp <=0 : continue\n",
    "        try:\n",
    "            gmm = GaussianMixture(n_components=n_comp, random_state=42, covariance_type='diag', n_init=3)\n",
    "            gmm.fit(features_array)\n",
    "            bic_val = gmm.bic(features_array)\n",
    "            bics.append(bic_val)\n",
    "            if bic_val < lowest_bic:\n",
    "                lowest_bic = bic_val\n",
    "                actual_n_components_for_gmm = n_comp\n",
    "        except ValueError as e:\n",
    "            messages.append(f\"Warning: Error fitting GMM with {n_comp} components: {e}. Skipping.\")\n",
    "            bics.append(np.infty)\n",
    "            continue\n",
    "\n",
    "    if actual_n_components_for_gmm == 0:\n",
    "        messages.append(f\"Warning: GMM fitting failed to find a suitable model. Fallback: Returning first {num_frames_to_select} frames from pool.\")\n",
    "        return frames_pool[:num_frames_to_select], frame_indices_pool[:num_frames_to_select], messages\n",
    "\n",
    "    messages.append(f\"Info: Best GMM by BIC has {actual_n_components_for_gmm} components (BIC: {lowest_bic:.2f})\")\n",
    "    \n",
    "    final_n_gmm_components = min(actual_n_components_for_gmm, num_frames_to_select)\n",
    "    final_n_gmm_components = max(1, final_n_gmm_components)\n",
    "    final_n_gmm_components = min(final_n_gmm_components, n_samples)\n",
    "\n",
    "    messages.append(f\"Info: Fitting final GMM with {final_n_gmm_components} components.\")\n",
    "    try:\n",
    "        final_gmm = GaussianMixture(n_components=final_n_gmm_components, random_state=42, covariance_type='diag', n_init=3)\n",
    "        final_gmm.fit(features_array)\n",
    "        labels = final_gmm.predict(features_array)\n",
    "        component_means = final_gmm.means_\n",
    "    except ValueError as e:\n",
    "        messages.append(f\"Error: Fitting final GMM with {final_n_gmm_components} components failed: {e}. Fallback.\")\n",
    "        return frames_pool[:num_frames_to_select], frame_indices_pool[:num_frames_to_select], messages\n",
    "\n",
    "    selected_frames_out = []\n",
    "    selected_frame_numbers_out = []\n",
    "    \n",
    "    for i in range(final_n_gmm_components):\n",
    "        cluster_member_indices = np.where(labels == i)[0]\n",
    "        if len(cluster_member_indices) > 0:\n",
    "            current_mean_idx = i if component_means.ndim > 1 and i < component_means.shape[0] else 0\n",
    "            current_mean = component_means[current_mean_idx]\n",
    "\n",
    "            distances = np.linalg.norm(features_array[cluster_member_indices] - current_mean, axis=1)\n",
    "            closest_in_cluster_idx_in_pool = cluster_member_indices[np.argmin(distances)]\n",
    "            \n",
    "            selected_frames_out.append(frames_pool[closest_in_cluster_idx_in_pool])\n",
    "            selected_frame_numbers_out.append(frame_indices_pool[closest_in_cluster_idx_in_pool])\n",
    "\n",
    "    if selected_frame_numbers_out:\n",
    "        sorted_indices = np.argsort(selected_frame_numbers_out)\n",
    "        selected_frames_out = [selected_frames_out[i] for i in sorted_indices]\n",
    "        selected_frame_numbers_out = [selected_frame_numbers_out[i] for i in sorted_indices]\n",
    "            \n",
    "    return selected_frames_out, selected_frame_numbers_out, messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_gsutil(remote_full_path, local_full_path, description=\"file\"):\n",
    "    os.makedirs(os.path.dirname(local_full_path), exist_ok=True)\n",
    "    command = [\"gsutil\", \"-q\", \"cp\", remote_full_path, local_full_path]\n",
    "    try:\n",
    "        # Using a timeout for gsutil can be beneficial\n",
    "        process = subprocess.run(command, check=True, capture_output=True, text=True, timeout=300) # 5 min timeout\n",
    "        return True, \"\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        error_msg = f\"Error downloading {description} ({os.path.basename(remote_full_path)}): gsutil stderr: {e.stderr.strip()}\"\n",
    "        return False, error_msg\n",
    "    except subprocess.TimeoutExpired:\n",
    "        error_msg = f\"Timeout downloading {description} ({os.path.basename(remote_full_path)})\"\n",
    "        return False, error_msg\n",
    "    except FileNotFoundError:\n",
    "        error_msg = \"Error: gsutil command not found. Is it installed and in your PATH?\"\n",
    "        return False, error_msg\n",
    "    except Exception as e: # Catch any other potential errors\n",
    "        error_msg = f\"Unexpected error downloading {description} ({os.path.basename(remote_full_path)}): {str(e)}\"\n",
    "        return False, error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dish_imagery(dish_id,\n",
    "                         remote_imagery_subdir,\n",
    "                         local_imagery_dir_full,\n",
    "                         image_filename_on_bucket):\n",
    "    # Use f-string for clarity in GCS path construction\n",
    "    remote_image_path = f\"{GSUTIL_BUCKET_BASE.rstrip('/')}/{remote_imagery_subdir.strip('/')}/{dish_id}/{image_filename_on_bucket}\"\n",
    "\n",
    "    local_dish_image_dir = os.path.join(local_imagery_dir_full, dish_id)\n",
    "    local_image_path = os.path.join(local_dish_image_dir, image_filename_on_bucket)\n",
    "\n",
    "    success, msg = download_file_gsutil(remote_image_path, local_image_path, description=f\"image {dish_id}/{image_filename_on_bucket}\")\n",
    "    return success, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_process_dish_videos(dish_id, num_frames_per_video_to_extract, dish_processing_messages_list):\n",
    "    dish_video_temp_dir = os.path.join(VIDEO_DIR_LOCAL_FULL, dish_id, \"temp_videos\")\n",
    "    dish_frames_output_dir = os.path.join(VIDEO_DIR_LOCAL_FULL, dish_id, FRAMES_SUBDIR)\n",
    "    os.makedirs(dish_video_temp_dir, exist_ok=True)\n",
    "    os.makedirs(dish_frames_output_dir, exist_ok=True)\n",
    "    \n",
    "    all_videos_processed_successfully_flag = True # True if all videos downloaded and processed without critical errors\n",
    "\n",
    "    if not VIDEO_FILENAMES: # Global config check\n",
    "        dish_processing_messages_list.append(f\"Dish {dish_id}: Video processing skipped (VIDEO_FILENAMES is empty).\")\n",
    "        return True # No videos to process means success in this context\n",
    "\n",
    "    for video_filename in VIDEO_FILENAMES:\n",
    "        # Use f-string for GCS path\n",
    "        video_remote_path = f\"{GSUTIL_BUCKET_BASE.rstrip('/')}/{VIDEO_SUBDIR_REMOTE.strip('/')}/{dish_id}/{video_filename}\"\n",
    "        video_local_path = os.path.join(dish_video_temp_dir, video_filename)\n",
    "        \n",
    "        download_success, dl_msg = download_file_gsutil(video_remote_path, video_local_path, \n",
    "                                                description=f\"video {video_filename} for dish {dish_id}\")\n",
    "        \n",
    "        if download_success:\n",
    "            try:\n",
    "                # select_diverse_frames_gmm now returns (frames, numbers, list_of_gmm_messages)\n",
    "                selected_frames, frame_numbers, gmm_messages_list = select_diverse_frames_gmm(\n",
    "                    video_local_path, \n",
    "                    num_frames_to_select=num_frames_per_video_to_extract,\n",
    "                    sample_every_nth=SAMPLE_EVERY_NTH_FRAME\n",
    "                )\n",
    "                \n",
    "                # Append all messages from GMM processing to the main dish messages list\n",
    "                for gmm_msg_item in gmm_messages_list:\n",
    "                    dish_processing_messages_list.append(f\"Dish {dish_id}, Video {video_filename} GMM: {gmm_msg_item}\")\n",
    "\n",
    "                if selected_frames:\n",
    "                    camera_id = os.path.splitext(video_filename)[0]\n",
    "                    for i_frame, (frame_content, frame_num) in enumerate(zip(selected_frames, frame_numbers)):\n",
    "                        frame_filename = f\"{camera_id}_frame_{frame_num:06d}.png\"\n",
    "                        frame_path = os.path.join(dish_frames_output_dir, frame_filename)\n",
    "                        # Ensure the directory for this specific frame exists (should be handled by outer makedirs)\n",
    "                        # os.makedirs(os.path.dirname(frame_path), exist_ok=True) # Redundant if dish_frames_output_dir is made\n",
    "                        # cv2.imwrite(frame_path, frame_content, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "                        cv2.imwrite(frame_path, frame_content, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "                    dish_processing_messages_list.append(f\"Dish {dish_id}, Video {video_filename}: Saved {len(selected_frames)} frames.\")\n",
    "                else:\n",
    "                    # Log if no frames were selected, GMM messages should explain why\n",
    "                    dish_processing_messages_list.append(f\"Dish {dish_id}, Video {video_filename}: No frames selected/saved by GMM (see GMM logs for details).\")\n",
    "                    # This isn't necessarily a critical failure of the video processing itself,\n",
    "                    # GMM might have validly found no diverse frames or video was too short/problematic.\n",
    "\n",
    "            except Exception as e: # Catch unexpected errors during frame selection/saving\n",
    "                dish_processing_messages_list.append(f\"Dish {dish_id}, Video {video_filename}: CRITICAL frame extraction/saving error: {e}\")\n",
    "                all_videos_processed_successfully_flag = False # Mark as failure for this video\n",
    "            finally:\n",
    "                if os.path.exists(video_local_path):\n",
    "                    try:\n",
    "                        os.remove(video_local_path)\n",
    "                    except OSError as e_del:\n",
    "                        dish_processing_messages_list.append(f\"Dish {dish_id}, Video {video_filename}: Warning - Failed to delete temp video {video_local_path}: {e_del}\")\n",
    "        else: # Download failed\n",
    "            dish_processing_messages_list.append(f\"Dish {dish_id}, Video {video_filename}: Download failed. {dl_msg}\")\n",
    "            all_videos_processed_successfully_flag = False # Mark as failure for this video\n",
    "        \n",
    "    # Cleanup temp video directory\n",
    "    if os.path.exists(dish_video_temp_dir):\n",
    "        try:\n",
    "            if not os.listdir(dish_video_temp_dir): # Only remove if empty\n",
    "                os.rmdir(dish_video_temp_dir)\n",
    "            else:\n",
    "                dish_processing_messages_list.append(f\"Dish {dish_id}: Warning - Temp video dir {dish_video_temp_dir} not empty after processing. Contents: {os.listdir(dish_video_temp_dir)}\")\n",
    "        except OSError as e_rmdir:\n",
    "            dish_processing_messages_list.append(f\"Dish {dish_id}: Warning - Could not remove temp video dir {dish_video_temp_dir}: {e_rmdir}\")\n",
    "\n",
    "    return all_videos_processed_successfully_flag\n",
    "\n",
    "\n",
    "def download_dish_data(dish_id_tuple):\n",
    "    \"\"\"\n",
    "    Wrapper for ProcessPoolExecutor. Takes a tuple (dish_id, num_frames_per_video).\n",
    "    Returns (dish_id, success_status, list_of_error_messages)\n",
    "    \"\"\"\n",
    "    dish_id, num_frames_per_video = dish_id_tuple\n",
    "    # print(f\"Processing dish: {dish_id}\") # Too noisy for parallel execution\n",
    "    overall_dish_success = True\n",
    "    error_messages = []\n",
    "\n",
    "    if FILENAME_ON_BUCKET:\n",
    "        for img_filename in FILENAME_ON_BUCKET:\n",
    "            success, msg = download_dish_imagery(dish_id, IMAGERY_SUBDIR_REMOTE, IMAGERY_DIR_LOCAL_FULL, img_filename)\n",
    "            if not success:\n",
    "                error_messages.append(f\"Dish {dish_id}, Image {img_filename}: {msg}\")\n",
    "                overall_dish_success = False\n",
    "    \n",
    "    if VIDEO_FILENAMES:\n",
    "        video_processing_success = download_and_process_dish_videos(dish_id, num_frames_per_video, error_messages)\n",
    "        if not video_processing_success:\n",
    "            # Specific errors are already added to error_messages by download_and_process_dish_videos\n",
    "            overall_dish_success = False\n",
    "            \n",
    "    return dish_id, overall_dish_success, error_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dish_ids_from_split_file(filepath, limit, random_sample=False):\n",
    "    all_dish_ids = []\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            all_dish_ids = [line.strip() for line in f if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Split file {filepath} not found.\")\n",
    "        return []\n",
    "\n",
    "    if not all_dish_ids:\n",
    "        print(f\"Warning: Split file {filepath} is empty.\")\n",
    "        return []\n",
    "\n",
    "    if random_sample:\n",
    "        if len(all_dish_ids) <= limit:\n",
    "            return all_dish_ids\n",
    "        return random.sample(all_dish_ids, limit)\n",
    "    else:\n",
    "        return all_dish_ids[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# train_dish_ids = get_dish_ids_from_split_file(\n",
    "#     TRAIN_SPLIT_FILE_RGB,\n",
    "#     NUM_DISHES_TO_DOWNLOAD_TRAIN,\n",
    "#     random_sample=RANDOM_SAMPLE_FROM_SPLIT\n",
    "# )\n",
    "train_dish_ids = get_dish_ids_from_split_file(\n",
    "    TEST_SPLIT_FILE_RGB,\n",
    "    NUM_DISHES_TO_DOWNLOAD_TRAIN,\n",
    "    random_sample=RANDOM_SAMPLE_FROM_SPLIT\n",
    ")\n",
    "\n",
    "if train_dish_ids:\n",
    "    print(f\"Selected {len(train_dish_ids)} dish IDs for training set processing.\")\n",
    "    print(f\"First few IDs: {train_dish_ids[:5]}\")\n",
    "else:\n",
    "    print(\"No training dish IDs loaded. Check split file path and content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_dish_ids:\n",
    "    print(f\"Selected {len(train_dish_ids)} unique dish IDs for processing.\")\n",
    "    # print(f\"First few IDs: {train_dish_ids_main[:5]}\") # Might be long if many\n",
    "else:\n",
    "    print(\"No dish IDs loaded. Check split file paths and content. Exiting.\")\n",
    "    exit() # Or handle as appropriate\n",
    "\n",
    "if train_dish_ids:\n",
    "    print(f\"\\nStarting download and processing for {len(train_dish_ids)} dishes.\")\n",
    "    print(f\"Using up to {MAX_WORKERS} worker processes.\")\n",
    "    print(f\"Overhead images to download per dish: {FILENAME_ON_BUCKET if FILENAME_ON_BUCKET else 'None'}\")\n",
    "    print(f\"Videos to process per dish: {len(VIDEO_FILENAMES)} ({VIDEO_FILENAMES if VIDEO_FILENAMES else 'None'})\")\n",
    "    print(f\"Frames to extract per video: {NUM_FRAMES_PER_VIDEO}\")\n",
    "    \n",
    "    successfully_processed_dish_count = 0\n",
    "    failed_dishes_info = [] # To store (dish_id, error_messages)\n",
    "\n",
    "    # Prepare arguments for map function (or submit)\n",
    "    # Each item for a worker needs to be (dish_id, NUM_FRAMES_PER_VIDEO)\n",
    "    tasks = [(dish_id, NUM_FRAMES_PER_VIDEO) for dish_id in train_dish_ids]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        # Using submit and as_completed to get results as they finish and update tqdm\n",
    "        futures = {executor.submit(download_dish_data, task): task[0] for task in tasks}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(tasks), desc=\"Processing Dishes\"):\n",
    "            processed_dish_id = futures[future] # Get the original dish_id for this future\n",
    "            try:\n",
    "                # The download_dish_data now returns (dish_id, success_status, list_of_error_messages)\n",
    "                # The dish_id returned by the function should match processed_dish_id\n",
    "                returned_dish_id, success, errors = future.result()\n",
    "                if success:\n",
    "                    successfully_processed_dish_count += 1\n",
    "                else:\n",
    "                    failed_dishes_info.append({'id': returned_dish_id, 'errors': errors})\n",
    "                if errors: # Log errors even for \"successful\" dishes if they had minor issues\n",
    "                        for error_msg in errors:\n",
    "                            print(f\"Log: {error_msg}\") # Print to console, or log to file\n",
    "            except Exception as e:\n",
    "                # This catches errors in the worker process execution itself, or if future.result() re-raises an unhandled one\n",
    "                failed_dishes_info.append({'id': processed_dish_id, 'errors': [f\"Critical error during processing: {e}\"]})\n",
    "                print(f\"Dish {processed_dish_id} CRITICAL FAILURE: {e}\") # Log critical failure\n",
    "\n",
    "    print(f\"\\n--- Processing Complete ---\")\n",
    "    print(f\"Successfully processed data for {successfully_processed_dish_count}/{len(train_dish_ids)} dishes.\")\n",
    "    \n",
    "    if failed_dishes_info:\n",
    "        print(f\"\\n--- Issues Encountered for {len(failed_dishes_info)} Dishes ---\")\n",
    "        for failure in failed_dishes_info:\n",
    "            print(f\"Dish ID: {failure['id']}\")\n",
    "            for err in failure['errors']:\n",
    "                print(f\"  - {err}\")\n",
    "\n",
    "else:\n",
    "    print(\"No training dish IDs to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "%pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Visualization Setup ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler # For feature scaling before PCA\n",
    "\n",
    "# Configure matplotlib for inline display in Jupyter\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Helper function to plot frames\n",
    "def plot_frames(frames, titles=None, figsize=(15, 5), max_cols=5):\n",
    "    \"\"\"Helper function to plot a list of frames.\"\"\"\n",
    "    num_frames = len(frames)\n",
    "    if num_frames == 0:\n",
    "        print(\"No frames to plot.\")\n",
    "        return\n",
    "    \n",
    "    # Determine number of rows and columns for the subplot\n",
    "    cols = min(num_frames, max_cols)\n",
    "    rows = (num_frames + cols - 1) // cols  # Ceiling division\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    axes = np.array(axes).flatten() # Flatten to 1D array for easy iteration\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        ax = axes[i]\n",
    "        # Convert BGR (OpenCV default) to RGB for matplotlib\n",
    "        ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "        if titles and i < len(titles):\n",
    "            ax.set_title(titles[i])\n",
    "    \n",
    "    # Turn off any remaining empty subplots\n",
    "    for j in range(num_frames, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Select a sample dish and video for detailed walkthrough ---\n",
    "SAMPLE_DISH_ID_VIS = \"dish_1551235699\"\n",
    "SAMPLE_VIDEO_FILENAME_VIS = \"camera_A.h264\" # A common camera angle\n",
    "\n",
    "# 1. Determine SAMPLE_DISH_ID_VIS\n",
    "# Try to use a dish from 'train_dish_ids' if it's populated and its frames were processed\n",
    "if 'train_dish_ids' in globals() and train_dish_ids:\n",
    "    # Iterate through a few processed IDs to find one with frames\n",
    "    # for potential_dish_id in train_dish_ids[2:3]: # Check first 5\n",
    "    #     expected_frames_dir = os.path.join(VIDEO_DIR_LOCAL_FULL, potential_dish_id, FRAMES_SUBDIR)\n",
    "    #     if os.path.exists(expected_frames_dir) and os.listdir(expected_frames_dir):\n",
    "    #         SAMPLE_DISH_ID_VIS = potential_dish_id\n",
    "    #         print(f\"Using processed dish '{SAMPLE_DISH_ID_VIS}' for visualization (frames found at {expected_frames_dir}).\")\n",
    "    #         break\n",
    "    if SAMPLE_DISH_ID_VIS is None and train_dish_ids : # If no frames found for first few, but list exists\n",
    "        potential_dish_id = train_dish_ids[0]\n",
    "        print(f\"Could not confirm processed frames for initial sample of 'train_dish_ids'.\")\n",
    "        print(f\"Proceeding with dish '{potential_dish_id}' but its video might need re-downloading if already processed and deleted.\")\n",
    "        SAMPLE_DISH_ID_VIS = potential_dish_id\n",
    "\n",
    "\n",
    "# Fallback if no suitable dish from train_dish_ids is found or train_dish_ids is empty\n",
    "if SAMPLE_DISH_ID_VIS is None:\n",
    "    SAMPLE_DISH_ID_VIS = \"00001\" # Fallback dish ID\n",
    "    print(f\"Falling back to default sample dish ID: '{SAMPLE_DISH_ID_VIS}'.\")\n",
    "\n",
    "# 2. Define paths for the visualization video\n",
    "# The visualization will use a video from the 'temp_videos' location, re-downloading if necessary.\n",
    "VIS_VIDEO_TEMP_DIR_FOR_DISH = os.path.join(VIDEO_DIR_LOCAL_FULL, SAMPLE_DISH_ID_VIS, \"temp_videos\")\n",
    "VIS_VIDEO_PATH = os.path.join(VIS_VIDEO_TEMP_DIR_FOR_DISH, SAMPLE_VIDEO_FILENAME_VIS)\n",
    "\n",
    "# Ensure the parent directory for the temporary visualization video exists\n",
    "os.makedirs(VIS_VIDEO_TEMP_DIR_FOR_DISH, exist_ok=True)\n",
    "\n",
    "# 3. Check if the video file exists. If not, attempt to download it for visualization.\n",
    "if not os.path.exists(VIS_VIDEO_PATH):\n",
    "    print(f\"Video for visualization ({VIS_VIDEO_PATH}) not found locally.\")\n",
    "    print(f\"Attempting to download {SAMPLE_VIDEO_FILENAME_VIS} for dish {SAMPLE_DISH_ID_VIS} for visualization purposes...\")\n",
    "    \n",
    "    # Construct the GCS path for the video\n",
    "    # Ensure GSUTIL_BUCKET_BASE and VIDEO_SUBDIR_REMOTE are defined from the main script\n",
    "    video_remote_gcs_path = f\"{GSUTIL_BUCKET_BASE.rstrip('/')}/{VIDEO_SUBDIR_REMOTE.strip('/')}/{SAMPLE_DISH_ID_VIS}/{SAMPLE_VIDEO_FILENAME_VIS}\"\n",
    "    \n",
    "    # Ensure download_file_gsutil function is defined from the main script\n",
    "    success, msg = download_file_gsutil(video_remote_gcs_path, VIS_VIDEO_PATH, description=f\"sample video for visualization\")\n",
    "    \n",
    "    if success:\n",
    "        print(f\"Successfully downloaded {SAMPLE_VIDEO_FILENAME_VIS} for dish {SAMPLE_DISH_ID_VIS} to {VIS_VIDEO_PATH}.\")\n",
    "    else:\n",
    "        print(f\"Failed to download sample video for visualization: {msg}\")\n",
    "        # This implies that subsequent steps requiring the raw video might fail.\n",
    "else:\n",
    "    print(f\"Video for visualization ({VIS_VIDEO_PATH}) already exists locally.\")\n",
    "\n",
    "# Final check and status message\n",
    "if os.path.exists(VIS_VIDEO_PATH):\n",
    "    print(f\"Using video file for visualization: {VIS_VIDEO_PATH}\")\n",
    "else:\n",
    "    print(f\"CRITICAL WARNING: Video file for visualization ({VIS_VIDEO_PATH}) is NOT available. \"\n",
    "          f\"The step-by-step raw video processing visualization will likely fail or be skipped.\")\n",
    "\n",
    "# Also ensure the directory for frames extracted by the *main script* exists for reference if needed,\n",
    "# but the visualization re-processes VIS_VIDEO_PATH.\n",
    "sample_dish_processed_frames_dir = os.path.join(VIDEO_DIR_LOCAL_FULL, SAMPLE_DISH_ID_VIS, FRAMES_SUBDIR)\n",
    "os.makedirs(sample_dish_processed_frames_dir, exist_ok=True) # For main script's output, not directly used by viz re-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Step 2a: Load video and extract candidate frames & features ---\n",
    "candidate_frames_pool = []\n",
    "candidate_features_pool = []\n",
    "candidate_frame_indices_pool = []\n",
    "\n",
    "if os.path.exists(VIS_VIDEO_PATH):\n",
    "    cap_vis = cv2.VideoCapture(VIS_VIDEO_PATH)\n",
    "    if not cap_vis.isOpened():\n",
    "        print(f\"Error: Could not open video {VIS_VIDEO_PATH} for visualization.\")\n",
    "    else:\n",
    "        frame_count_vis = 0\n",
    "        while True:\n",
    "            ret, frame = cap_vis.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if frame_count_vis % SAMPLE_EVERY_NTH_FRAME == 0: # Same sampling as in main script\n",
    "                try:\n",
    "                    # We need the frame itself for visualization, and features for analysis\n",
    "                    # Make sure extract_frame_features is defined (it should be from original notebook)\n",
    "                    features = extract_frame_features(frame) \n",
    "                    candidate_frames_pool.append(frame)\n",
    "                    candidate_features_pool.append(features)\n",
    "                    candidate_frame_indices_pool.append(frame_count_vis)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not extract features for frame {frame_count_vis} from {VIS_VIDEO_PATH}. Error: {e}\")\n",
    "            frame_count_vis += 1\n",
    "        cap_vis.release()\n",
    "        print(f\"Extracted {len(candidate_frames_pool)} candidate frames (and their features) from {VIS_VIDEO_PATH}.\")\n",
    "        \n",
    "        if candidate_frames_pool:\n",
    "            print(\"Showing first 5 candidate frames from the pool:\")\n",
    "            plot_frames(candidate_frames_pool[:5], titles=[f\"Frame {candidate_frame_indices_pool[i]}\" for i in range(min(5, len(candidate_frames_pool)))])\n",
    "        else:\n",
    "            print(\"No candidate frames could be extracted. Further visualization steps might fail.\")\n",
    "else:\n",
    "    print(f\"Video {VIS_VIDEO_PATH} not found. Skipping candidate frame extraction visualization.\")\n",
    "\n",
    "candidate_features_array = np.array(candidate_features_pool)\n",
    "# Scale features before PCA for better results\n",
    "if candidate_features_array.ndim > 1 and candidate_features_array.shape[0] > 1 :\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(candidate_features_array)\n",
    "else:\n",
    "    scaled_features = candidate_features_array # Not enough data to scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Step 2c: PCA and Visualize Feature Space ---\n",
    "if 'scaled_features' in globals() and scaled_features.shape[0] > 1 and scaled_features.shape[1] > 1: # Need at least 2 samples and 2 features for PCA\n",
    "    pca_vis = PCA(n_components=2, random_state=42)\n",
    "    features_2d = pca_vis.fit_transform(scaled_features) # Use scaled features\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.scatterplot(x=features_2d[:, 0], y=features_2d[:, 1], alpha=0.7)\n",
    "    plt.title(f'2D PCA of Frame Features from {os.path.basename(VIS_VIDEO_PATH)}')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Each point in the scatter plot represents a frame from our candidate pool.\")\n",
    "    print(\"Clusters of points suggest groups of visually similar frames.\")\n",
    "else:\n",
    "    print(\"Not enough data or features to perform PCA and visualize feature space.\")\n",
    "    features_2d = None # So later cells can check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Step 2d: GMM Clustering and BIC for Model Selection ---\n",
    "if 'features_2d' in globals() and features_2d is not None and 'scaled_features' in globals() and scaled_features.shape[0] > 1:\n",
    "    n_samples_vis = scaled_features.shape[0]\n",
    "    \n",
    "    max_components_to_test = min(10, n_samples_vis -1 if n_samples_vis > 1 else 1) \n",
    "    max_components_to_test = max(1, max_components_to_test)\n",
    "    \n",
    "    if n_samples_vis <= 1:\n",
    "        print(\"Not enough samples for GMM. Skipping GMM visualization.\")\n",
    "    else:\n",
    "        test_n_components_range = range(1, max_components_to_test + 1)\n",
    "        \n",
    "        bics_vis = []\n",
    "        lowest_bic_vis = np.infty\n",
    "        best_n_components_vis = 0\n",
    "\n",
    "        print(f\"Evaluating GMM with {list(test_n_components_range)} components using BIC...\")\n",
    "        for n_comp_vis in test_n_components_range:\n",
    "            if n_comp_vis == 0: continue\n",
    "            if n_comp_vis > n_samples_vis : \n",
    "                bics_vis.append(np.nan)\n",
    "                continue\n",
    "            try:\n",
    "                # Make sure GaussianMixture is imported\n",
    "                gmm_vis = GaussianMixture(n_components=n_comp_vis, random_state=42, covariance_type='diag', n_init=3)\n",
    "                gmm_vis.fit(scaled_features) \n",
    "                bic_val = gmm_vis.bic(scaled_features)\n",
    "                bics_vis.append(bic_val)\n",
    "                if bic_val < lowest_bic_vis:\n",
    "                    lowest_bic_vis = bic_val\n",
    "                    best_n_components_vis = n_comp_vis\n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: GMM with {n_comp_vis} components failed: {e}\")\n",
    "                bics_vis.append(np.nan)\n",
    "\n",
    "        if best_n_components_vis > 0:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            # Filter out NaN BICs for plotting if any occurred\n",
    "            valid_bics_indices = [i for i, bic in enumerate(bics_vis) if not np.isnan(bic)]\n",
    "            valid_components_range = [test_n_components_range[i] for i in valid_bics_indices]\n",
    "            valid_bics_values = [bics_vis[i] for i in valid_bics_indices]\n",
    "\n",
    "            if valid_components_range: # Ensure there's something to plot\n",
    "                plt.plot(valid_components_range, valid_bics_values, marker='o')\n",
    "                plt.title('BIC Scores for GMM Components')\n",
    "                plt.xlabel('Number of Components')\n",
    "                plt.ylabel('BIC Score (Lower is Better)')\n",
    "                plt.xticks(valid_components_range)\n",
    "                plt.axvline(best_n_components_vis, color='r', linestyle='--', label=f'Best N Components: {best_n_components_vis}')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"No valid BIC scores to plot.\")\n",
    "\n",
    "            print(f\"Best number of GMM components according to BIC: {best_n_components_vis}\")\n",
    "\n",
    "            final_gmm_vis = GaussianMixture(n_components=2, random_state=42, covariance_type='diag', n_init=3)\n",
    "            final_gmm_vis.fit(scaled_features)\n",
    "            labels_vis = final_gmm_vis.predict(scaled_features)\n",
    "\n",
    "            if features_2d is not None:\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                sns.scatterplot(x=features_2d[:, 0], y=features_2d[:, 1], hue=labels_vis, palette='viridis', alpha=0.7, legend='full')\n",
    "                plt.title(f'Frame Clusters (GMM) on 2D PCA ({best_n_components_vis} clusters found)')\n",
    "                plt.xlabel('Principal Component 1')\n",
    "                plt.ylabel('Principal Component 2')\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"PCA plot not available for cluster visualization.\")\n",
    "        else:\n",
    "            print(\"Could not determine the best number of GMM components. Skipping GMM visualization.\")\n",
    "else:\n",
    "    print(\"Skipping GMM visualization as previous steps might have failed or yielded insufficient data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Step 2d: GMM Clustering and BIC for Model Selection ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib.patches import Ellipse # For drawing ellipses\n",
    "# import matplotlib.colors # Might be useful for advanced color handling, not strictly needed here\n",
    "\n",
    "# Helper function to draw GMM ellipses\n",
    "def plot_gmm_ellipse(ax, mean_pca, covariance_pca, color, n_std=2.0, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots an n_std sigma ellipse of a 2D Gaussian component on the given axes.\n",
    "    - ax: Matplotlib axes object\n",
    "    - mean_pca: 2D mean in PCA space (center of the ellipse)\n",
    "    - covariance_pca: 2x2 covariance matrix in PCA space\n",
    "    - color: Color for the ellipse edge\n",
    "    - n_std: Number of standard deviations for the ellipse size (e.g., 2.0 for approx 95% region)\n",
    "    \"\"\"\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_pca) # Use eigh for symmetric matrices\n",
    "    \n",
    "    # Ensure eigenvalues are non-negative (can be slightly negative due to numerical issues)\n",
    "    eigenvalues = np.maximum(eigenvalues, 0)\n",
    "\n",
    "    # Order eigenvalues and eigenvectors: largest eigenvalue first\n",
    "    order = eigenvalues.argsort()[::-1]\n",
    "    eigenvalues = eigenvalues[order]\n",
    "    eigenvectors = eigenvectors[:, order]\n",
    "\n",
    "    # Angle of the first principal component (largest eigenvector)\n",
    "    # The eigenvector gives the direction (cos, sin), arctan2 gives the angle\n",
    "    vx, vy = eigenvectors[:, 0] \n",
    "    angle = np.degrees(np.arctan2(vy, vx))\n",
    "\n",
    "    # Width and height of the ellipse (full diameters, not semi-axes for Ellipse patch)\n",
    "    # Eigenvalues are variances, so sqrt(eigenvalues) are standard deviations\n",
    "    width, height = 2 * n_std * np.sqrt(eigenvalues)\n",
    "    \n",
    "    ellipse = Ellipse(xy=mean_pca, width=width, height=height, angle=angle,\n",
    "                      facecolor='none', edgecolor=color, lw=2, **kwargs)\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "\n",
    "# Assuming 'features_2d', 'scaled_features', and 'pca_2d' (the PCA transformer object)\n",
    "# are defined in previous cells/steps.\n",
    "if ('features_2d' in globals() and features_2d is not None and\n",
    "    'scaled_features' in globals() and scaled_features is not None and\n",
    "    'pca_2d' in globals() and pca_2d is not None and # Crucial for projecting GMM parameters\n",
    "    scaled_features.shape[0] > 1): # Ensure there's enough data\n",
    "    \n",
    "    n_samples_vis = scaled_features.shape[0]\n",
    "    \n",
    "    # Determine max components to test, ensure it's at least 1 and not more than n_samples-1\n",
    "    max_components_to_test = min(10, n_samples_vis -1 if n_samples_vis > 1 else 1) \n",
    "    max_components_to_test = max(1, max_components_to_test) # Ensure it's at least 1\n",
    "    \n",
    "    # This initial check effectively handles n_samples_vis <= 1 or situations where GMM isn't meaningful\n",
    "    if n_samples_vis <= 1 or max_components_to_test == 0 : # max_components_to_test can't be 0 with current logic\n",
    "        print(\"Not enough samples for GMM or max_components_to_test is 0. Skipping GMM visualization.\")\n",
    "    else:\n",
    "        test_n_components_range = range(1, max_components_to_test + 1)\n",
    "        \n",
    "        bics_vis = []\n",
    "        lowest_bic_vis = np.infty\n",
    "        best_n_components_vis = 0 # Initialize, indicates no best model found yet\n",
    "\n",
    "        print(f\"Evaluating GMM with {list(test_n_components_range)} components using BIC...\")\n",
    "        for n_comp_vis in test_n_components_range:\n",
    "            # n_comp_vis will always be <= n_samples_vis due to max_components_to_test logic\n",
    "            try:\n",
    "                gmm_vis = GaussianMixture(n_components=n_comp_vis, random_state=42, \n",
    "                                          covariance_type='diag', n_init=10) # n_init=10 for robustness\n",
    "                gmm_vis.fit(scaled_features) \n",
    "                bic_val = gmm_vis.bic(scaled_features)\n",
    "                bics_vis.append(bic_val)\n",
    "                if not np.isnan(bic_val) and bic_val < lowest_bic_vis:\n",
    "                    lowest_bic_vis = bic_val\n",
    "                    best_n_components_vis = n_comp_vis\n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: GMM with {n_comp_vis} components failed: {e}\")\n",
    "                bics_vis.append(np.nan)\n",
    "\n",
    "        if best_n_components_vis > 0: # Proceed only if a best model was found\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            # Filter out NaN BICs for plotting\n",
    "            valid_indices = [i for i, bic in enumerate(bics_vis) if not np.isnan(bic)]\n",
    "            # Components corresponding to valid BICs\n",
    "            plot_components = [test_n_components_range[i] for i in valid_indices]\n",
    "            plot_bics = [bics_vis[i] for i in valid_indices]\n",
    "\n",
    "            if plot_components: # Ensure there's something to plot\n",
    "                plt.plot(plot_components, plot_bics, marker='o')\n",
    "                plt.title('BIC Scores for GMM Components')\n",
    "                plt.xlabel('Number of Components')\n",
    "                plt.ylabel('BIC Score (Lower is Better)')\n",
    "                plt.xticks(plot_components)\n",
    "                plt.axvline(best_n_components_vis, color='r', linestyle='--', \n",
    "                            label=f'Best N Components: {best_n_components_vis}')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"No valid BIC scores to plot.\")\n",
    "\n",
    "            print(f\"Best number of GMM components according to BIC: {best_n_components_vis}\")\n",
    "\n",
    "            # Fit final GMM with the best number of components\n",
    "            final_gmm_vis = GaussianMixture(n_components=best_n_components_vis, # Use determined best_n_components_vis\n",
    "                                            random_state=42, covariance_type='diag', n_init=10)\n",
    "            final_gmm_vis.fit(scaled_features)\n",
    "            labels_vis = final_gmm_vis.predict(scaled_features)\n",
    "\n",
    "            # features_2d should not be None if we passed the initial check\n",
    "            fig, ax = plt.subplots(figsize=(12, 8)) # Get both figure and axes\n",
    "\n",
    "            # Define a palette for consistent coloring\n",
    "            # Ensure n_colors for palette is at least 1\n",
    "            num_colors_for_palette = max(1, best_n_components_vis)\n",
    "            palette = sns.color_palette('viridis', n_colors=num_colors_for_palette)\n",
    "            \n",
    "            sns.scatterplot(x=features_2d[:, 0], y=features_2d[:, 1], hue=labels_vis, \n",
    "                            palette=palette, alpha=0.7, legend='full', ax=ax)\n",
    "            \n",
    "            ax.set_title(f'Frame Clusters (GMM) on 2D PCA ({best_n_components_vis} clusters found)')\n",
    "            ax.set_xlabel('Principal Component 1')\n",
    "            ax.set_ylabel('Principal Component 2')\n",
    "\n",
    "            # Project GMM means and covariances to PCA space and plot ellipses\n",
    "            # final_gmm_vis.means_ are (n_components, n_features_original)\n",
    "            # final_gmm_vis.covariances_ are (n_components, n_features_original) for 'diag' type\n",
    "            \n",
    "            # Transform GMM means from original feature space to 2D PCA space\n",
    "            # pca_2d is the fitted PCA object: pca_2d.transform expects (n_samples, n_features_original)\n",
    "            means_pca_space = pca_2d.transform(final_gmm_vis.means_) # Result is (n_components, 2)\n",
    "            \n",
    "            # pca_2d.components_ has shape (n_pca_components, n_features_original), e.g., (2, D)\n",
    "            \n",
    "            for i in range(best_n_components_vis):\n",
    "                mean_pca_component = means_pca_space[i] # Center of ellipse in 2D\n",
    "                \n",
    "                # Covariance for component i in original feature space (diagonal elements)\n",
    "                cov_orig_diag_elements_i = final_gmm_vis.covariances_[i] # Shape: (n_features_original,)\n",
    "                # Construct full diagonal covariance matrix in original space\n",
    "                cov_orig_full_diag_i = np.diag(cov_orig_diag_elements_i) # Shape: (D, D)\n",
    "                \n",
    "                # Project this original covariance to PCA space: C_pca = P @ C_orig @ P.T\n",
    "                # P is pca_2d.components_\n",
    "                cov_pca_component = pca_2d.components_ @ cov_orig_full_diag_i @ pca_2d.components_.T\n",
    "                # cov_pca_component should be a (2, 2) matrix\n",
    "                \n",
    "                # Color for this component's ellipse (matches scatter plot hue)\n",
    "                # The GMM components are typically indexed 0 to N-1, matching palette indices\n",
    "                component_color = palette[i % len(palette)]\n",
    "\n",
    "                plot_gmm_ellipse(ax, mean_pca_component, cov_pca_component, \n",
    "                                 color=component_color, n_std=2.0) # 2 standard deviations\n",
    "\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Could not determine the best number of GMM components. Skipping GMM visualization.\")\n",
    "else:\n",
    "    # More informative message if conditions are not met\n",
    "    missing_reasons = []\n",
    "    if 'features_2d' not in globals() or features_2d is None:\n",
    "        missing_reasons.append(\"features_2d (PCA-reduced data) is missing\")\n",
    "    if 'scaled_features' not in globals() or scaled_features is None:\n",
    "        missing_reasons.append(\"scaled_features (input to GMM) is missing\")\n",
    "    elif 'scaled_features' in globals() and scaled_features is not None and scaled_features.shape[0] <= 1:\n",
    "        missing_reasons.append(\"scaled_features has insufficient samples (<=1)\")\n",
    "    if 'pca_2d' not in globals() or pca_2d is None:\n",
    "        missing_reasons.append(\"pca_2d (PCA transformer object) is missing, needed for ellipse projection\")\n",
    "        \n",
    "    if missing_reasons:\n",
    "        print(f\"Skipping GMM visualization. Reasons: {'; '.join(missing_reasons)}.\")\n",
    "    else: \n",
    "        # This case should ideally not be reached if the main 'if' condition is structured well\n",
    "        print(\"Skipping GMM visualization as previous steps might have failed or yielded insufficient data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Step 2e: Selecting representative frames (simplified illustration) ---\n",
    "selected_vis_frames = []\n",
    "selected_vis_frame_indices = []\n",
    "\n",
    "if 'final_gmm_vis' in globals() and 'labels_vis' in globals() and 'candidate_frames_pool' in globals() and candidate_frames_pool:\n",
    "    num_actual_clusters = final_gmm_vis.n_components\n",
    "    \n",
    "    for i in range(num_actual_clusters):\n",
    "        cluster_member_indices_in_pool = np.where(labels_vis == i)[0]\n",
    "        if len(cluster_member_indices_in_pool) > 0:\n",
    "            cluster_features = scaled_features[cluster_member_indices_in_pool]\n",
    "            component_mean = final_gmm_vis.means_[i]\n",
    "            distances = np.linalg.norm(cluster_features - component_mean, axis=1)\n",
    "            closest_in_cluster_local_idx = np.argmin(distances)\n",
    "            original_pool_idx = cluster_member_indices_in_pool[closest_in_cluster_local_idx]\n",
    "            \n",
    "            selected_vis_frames.append(candidate_frames_pool[original_pool_idx])\n",
    "            selected_vis_frame_indices.append(candidate_frame_indices_pool[original_pool_idx])\n",
    "\n",
    "    if selected_vis_frames:\n",
    "        sorted_indices = np.argsort(selected_vis_frame_indices)\n",
    "        selected_vis_frames_sorted = [selected_vis_frames[i] for i in sorted_indices]\n",
    "        selected_vis_frame_indices_sorted = [selected_vis_frame_indices[i] for i in sorted_indices]\n",
    "        \n",
    "        print(f\"Selected {len(selected_vis_frames_sorted)} representative frames based on GMM clusters (simplified illustration):\")\n",
    "        plot_frames(selected_vis_frames_sorted, \n",
    "                    titles=[f\"Cluster Rep. (Frame {idx})\" for idx in selected_vis_frame_indices_sorted],\n",
    "                    max_cols=max(1, len(selected_vis_frames_sorted))) # Show all in one row if possible\n",
    "    else:\n",
    "        print(\"No frames selected in this illustrative step (perhaps GMM failed or no clusters found).\")\n",
    "else:\n",
    "    print(\"GMM results not available, skipping illustrative frame selection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Step 3: Show results using the script's main function ---\n",
    "# Ensure NUM_FRAMES_PER_VIDEO and SAMPLE_EVERY_NTH_FRAME are defined from original notebook\n",
    "# Default if not (though they should be):\n",
    "if 'NUM_FRAMES_PER_VIDEO' not in globals(): NUM_FRAMES_PER_VIDEO = 5\n",
    "if 'SAMPLE_EVERY_NTH_FRAME' not in globals(): SAMPLE_EVERY_NTH_FRAME = 5\n",
    "\n",
    "\n",
    "print(f\"Running the script's 'select_diverse_frames_gmm' function for {VIS_VIDEO_PATH}...\")\n",
    "print(f\"Targeting NUM_FRAMES_PER_VIDEO = {NUM_FRAMES_PER_VIDEO}\")\n",
    "\n",
    "if os.path.exists(VIS_VIDEO_PATH):\n",
    "    # Make sure select_diverse_frames_gmm is defined (from original notebook)\n",
    "    final_selected_frames, final_selected_frame_numbers, messages = select_diverse_frames_gmm(\n",
    "        VIS_VIDEO_PATH,\n",
    "        num_frames_to_select=NUM_FRAMES_PER_VIDEO, \n",
    "        sample_every_nth=SAMPLE_EVERY_NTH_FRAME    \n",
    "    )\n",
    "    \n",
    "    print(\"\\nMessages from select_diverse_frames_gmm:\")\n",
    "    for msg in messages:\n",
    "        print(f\"- {msg}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if final_selected_frames:\n",
    "        print(f\"Final selected diverse frames ({len(final_selected_frames)} frames):\")\n",
    "        \n",
    "        first_frame_display = None\n",
    "        if 'candidate_frames_pool' in globals() and candidate_frames_pool:\n",
    "            first_frame_display = candidate_frames_pool[0]\n",
    "        \n",
    "        if first_frame_display is not None:\n",
    "            plot_frames([first_frame_display], titles=[\"Original Video (First Sampled Frame)\"], figsize=(6,4), max_cols=1)\n",
    "\n",
    "        plot_frames(final_selected_frames, \n",
    "                    titles=[f\"Selected Frame {num}\" for num in final_selected_frame_numbers],\n",
    "                    max_cols=max(1, NUM_FRAMES_PER_VIDEO)) \n",
    "    else:\n",
    "        print(\"No frames were selected by 'select_diverse_frames_gmm'. Check messages above for reasons.\")\n",
    "else:\n",
    "    print(f\"Video {VIS_VIDEO_PATH} not found. Cannot run 'select_diverse_frames_gmm'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
