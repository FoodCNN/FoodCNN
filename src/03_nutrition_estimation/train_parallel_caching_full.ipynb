{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter # For counting image types\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "\n",
    "os.environ['NCCL_DEBUG'] = 'WARN'\n",
    "PROCESS_DEVICE = None\n",
    "\n",
    "def setup_distributed(backend='nccl'):\n",
    "    \"\"\"Initializes the distributed environment.\"\"\"\n",
    "    global PROCESS_DEVICE\n",
    "    if \"RANK\" not in os.environ or \"WORLD_SIZE\" not in os.environ or \"LOCAL_RANK\" not in os.environ:\n",
    "        print(\"Distributed environment variables (RANK, WORLD_SIZE, LOCAL_RANK) not found. Running in non-distributed mode.\")\n",
    "        PROCESS_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return 0, 1, PROCESS_DEVICE, False\n",
    "\n",
    "    rank = int(os.environ[\"RANK\"])\n",
    "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    device = torch.device(f\"cuda:{local_rank}\")\n",
    "    PROCESS_DEVICE = device\n",
    "\n",
    "    print(f\"Initializing process group: backend={backend}, rank={rank}, world_size={world_size}, local_rank={local_rank}, device={device}\")\n",
    "    dist.init_process_group(backend=backend)\n",
    "    return rank, world_size, device, True\n",
    "\n",
    "def cleanup_distributed():\n",
    "    if dist.is_initialized():\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "def reduce_tensor(tensor, world_size):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n",
    "    rt /= world_size\n",
    "    return rt\n",
    "\n",
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description=\"Train nutrition estimation models with DDP.\")\n",
    "    parser.add_argument('--model_name', type=str, required=True,\n",
    "                        choices=['SimpleConvNet', 'DeepConvNet', 'MobileNetLike', 'ResNetFromScratch', 'ResNetPretrained'],\n",
    "                        help='Name of the model to train.')\n",
    "    parser.add_argument('--base_dir', type=str, default=\"/users/eleves-b/2023/georgii.kuznetsov/CNN_nutrition/nutrition5k\", # Example, adjust\n",
    "                        help='Base directory for the dataset.')\n",
    "    parser.add_argument('--output_dir', type=str, default=\"distributed_output_sides\",\n",
    "                        help='Directory to save models, history, and plots.')\n",
    "    parser.add_argument('--epochs', type=int, default=100, help='Number of training epochs.')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, help='Learning rate.')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='Batch size *per GPU*.')\n",
    "    parser.add_argument('--num_workers', type=int, default=2, help='Number of workers for DataLoader *per GPU*.')\n",
    "    parser.add_argument('--save_plots', action='store_true', help='Save plots to files.')\n",
    "    parser.add_argument('--backend', type=str, default='nccl', choices=['nccl', 'gloo'], help='Distributed backend.')\n",
    "    parser.add_argument('--enable_gpu_caching', action='store_true',\n",
    "                        help='Enable caching of transformed images to GPU VRAM (best with num_workers=0).')\n",
    "\n",
    "    # --- NEW: Arguments for side angles ---\n",
    "    parser.add_argument('--include_side_angles', action='store_true',\n",
    "                        help='Include side angle images in the dataset if available.')\n",
    "    parser.add_argument('--num_side_angles_per_dish', type=int, default=20,\n",
    "                        help='Max number of random side angle frames to use per dish if --include_side_angles is set. Set to 0 to use all available.')\n",
    "\n",
    "    if any('jupyter' in arg for arg in sys.argv) or 'ipykernel_launcher.py' in sys.argv[0]:\n",
    "        print(\"Running in interactive mode (e.g., Jupyter). Using default args for non-distributed test.\")\n",
    "        args = parser.parse_args([\n",
    "            '--model_name', 'SimpleConvNet',\n",
    "            '--epochs', '2',\n",
    "            '--output_dir', 'interactive_test_output_ddp_sides', # Changed output dir\n",
    "            '--include_side_angles', # For testing side angles\n",
    "            '--num_side_angles_per_dish', '2', # For testing\n",
    "            # '--enable_gpu_caching' # Optional for interactive\n",
    "            # '--save_plots'\n",
    "        ])\n",
    "        current_rank, current_world_size, current_device, is_distributed_mode = 0, 1, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), False\n",
    "        global PROCESS_DEVICE\n",
    "        PROCESS_DEVICE = current_device\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "        current_rank, current_world_size, current_device, is_distributed_mode = setup_distributed(backend=args.backend)\n",
    "\n",
    "    return args, current_rank, current_world_size, current_device, is_distributed_mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self, num_outputs=4):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class DeepConvNet(nn.Module): # Shortened for brevity\n",
    "    def __init__(self, num_outputs=4):\n",
    "        super(DeepConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.res_block1 = self._make_residual_block(64, 128)\n",
    "        self.res_block2 = self._make_residual_block(128, 256)\n",
    "        self.res_block3 = self._make_residual_block(256, 512)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_outputs)\n",
    "    def _make_residual_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1), nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1), nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.res_block1(x); x = self.res_block2(x); x = self.res_block3(x)\n",
    "        x = self.avgpool(x); x = x.view(x.size(0), -1); x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MobileNetLike(nn.Module): # Shortened for brevity\n",
    "    def __init__(self, num_outputs=4):\n",
    "        super(MobileNetLike, self).__init__()\n",
    "        def depthwise_separable_conv(in_c, out_c, s=1):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, in_c, 3, stride=s, padding=1, groups=in_c), nn.BatchNorm2d(in_c), nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_c, out_c, 1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True)\n",
    "            )\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=2, padding=1); self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.dw_conv2 = depthwise_separable_conv(32, 64, s=2)\n",
    "        self.dw_conv3 = depthwise_separable_conv(64, 128, s=2)\n",
    "        self.dw_conv4 = depthwise_separable_conv(128, 256, s=2)\n",
    "        self.dw_conv5 = depthwise_separable_conv(256, 512, s=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)); self.fc = nn.Linear(512, num_outputs)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dw_conv2(x); x = self.dw_conv3(x); x = self.dw_conv4(x); x = self.dw_conv5(x)\n",
    "        x = self.avgpool(x); x = x.view(x.size(0), -1); x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ResNetFromScratch(nn.Module): # Shortened for brevity\n",
    "    def __init__(self, num_outputs=4, use_pretrained=False):\n",
    "        super(ResNetFromScratch, self).__init__()\n",
    "        weights = models.ResNet34_Weights.IMAGENET1K_V1 if use_pretrained else None\n",
    "        self.backbone = models.resnet34(weights=weights)\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256), nn.ReLU(), nn.Dropout(0.5), nn.Linear(256, num_outputs)\n",
    "        )\n",
    "    def forward(self, x): return self.backbone(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nutrition_csv(file_path):\n",
    "    dishes = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            if not parts[0].startswith('dish_'): continue\n",
    "            dish_id = parts[0]\n",
    "            try:\n",
    "                dish_calories = float(parts[1]); dish_weight = float(parts[2])\n",
    "                dish_fat = float(parts[3]); dish_carbs = float(parts[4]); dish_protein = float(parts[5])\n",
    "            except (ValueError, IndexError): continue # Skip malformed lines\n",
    "            if dish_weight == 0: continue\n",
    "            dishes.append({\n",
    "                'dish_id': dish_id, 'calories': dish_calories, 'weight': dish_weight,\n",
    "                'fat': dish_fat, 'carbs': dish_carbs, 'protein': dish_protein,\n",
    "                'calories_per_100g': (dish_calories / dish_weight) * 100,\n",
    "                'fat_per_100g': (dish_fat / dish_weight) * 100,\n",
    "                'carbs_per_100g': (dish_carbs / dish_weight) * 100,\n",
    "                'protein_per_100g': (dish_protein / dish_weight) * 100\n",
    "            })\n",
    "    return pd.DataFrame(dishes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NutritionDataset(Dataset):\n",
    "    def __init__(self, items_list, all_labels_array_source, transform=None,\n",
    "                 enable_gpu_cache=False, device=None,\n",
    "                 process_rank_for_log=0, is_distributed_for_log=False):\n",
    "        self.items_list = items_list # List of dicts {'dish_id', 'label_idx', 'image_type', 'image_path'}\n",
    "        self.all_labels_array_source = all_labels_array_source # Full np.array of labels\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        self.process_rank_for_log = process_rank_for_log\n",
    "        self.is_distributed_for_log = is_distributed_for_log\n",
    "\n",
    "        self.enable_gpu_cache = enable_gpu_cache and torch.cuda.is_available() and self.device is not None\n",
    "        self.image_cache_gpu = {}\n",
    "\n",
    "        if self.enable_gpu_cache:\n",
    "            # Each rank caches the images relevant to its own dataset instance (which is the full train/val set)\n",
    "            # The sampler then selects indices from this.\n",
    "            # If num_workers > 0, caching happens on-the-fly in __getitem__.\n",
    "            # If num_workers == 0 (recommended for GPU caching), pre-cache here.\n",
    "            # This logic assumes num_workers will be forced to 0 if GPU caching is on.\n",
    "            unique_image_paths_to_cache = sorted(list(set(item['image_path'] for item in self.items_list)))\n",
    "\n",
    "            if self.process_rank_for_log == 0 or not self.is_distributed_for_log:\n",
    "                print(f\"Rank {self.process_rank_for_log}: GPU Caching ENABLED. Attempting to cache {len(unique_image_paths_to_cache)} unique images to {self.device}...\")\n",
    "                cache_iterator = tqdm(unique_image_paths_to_cache, desc=f\"Rank {self.process_rank_for_log} Caching to GPU\", disable=False)\n",
    "            else: # Other ranks cache silently or with minimal logging\n",
    "                print(f\"Rank {self.process_rank_for_log}: GPU Caching ENABLED. Attempting to cache {len(unique_image_paths_to_cache)} unique images to {self.device}...\")\n",
    "                cache_iterator = unique_image_paths_to_cache\n",
    "\n",
    "            num_cached_successfully = 0\n",
    "            oom_occurred = False\n",
    "            for image_path in cache_iterator:\n",
    "                if oom_occurred: continue\n",
    "                try:\n",
    "                    self._load_and_cache_to_gpu(image_path)\n",
    "                    num_cached_successfully += 1\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e).lower():\n",
    "                        print(f\"WARNING (Rank {self.process_rank_for_log}): GPU OOM caching {image_path}. Stopping caching. Cached: {num_cached_successfully}.\")\n",
    "                        oom_occurred = True\n",
    "                        if image_path in self.image_cache_gpu: del self.image_cache_gpu[image_path] # Clean up failed cache attempt\n",
    "                    else: print(f\"WARNING (Rank {self.process_rank_for_log}): RuntimeError caching {image_path}: {e}. Skipping.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"WARNING (Rank {self.process_rank_for_log}): Unexpected error caching {image_path}: {e}. Skipping.\")\n",
    "\n",
    "            if self.process_rank_for_log == 0 or not self.is_distributed_for_log:\n",
    "                print(f\"Rank {self.process_rank_for_log}: GPU Caching Summary: {num_cached_successfully}/{len(unique_image_paths_to_cache)} unique images cached.\")\n",
    "            if oom_occurred:\n",
    "                 print(f\"Rank {self.process_rank_for_log}: Caching stopped due to OOM. Some images will be loaded on-demand if accessed.\")\n",
    "\n",
    "    def _load_image_pil(self, image_path_arg): # Takes full image_path\n",
    "        try:\n",
    "            image = Image.open(image_path_arg).convert(\"RGB\")\n",
    "            return image\n",
    "        except FileNotFoundError:\n",
    "            # Potentially reduce logging frequency for non-rank 0 if it becomes too verbose\n",
    "            print(f\"ERROR (Rank {self.process_rank_for_log}): Image not found at {image_path_arg}. Using dummy.\")\n",
    "            return Image.new(\"RGB\", (224, 224), color=(0, 0, 0))\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR (Rank {self.process_rank_for_log}): Loading image {image_path_arg} failed: {e}. Using dummy.\")\n",
    "            return Image.new(\"RGB\", (224, 224), color=(0, 0, 0))\n",
    "\n",
    "    def _load_and_cache_to_gpu(self, image_path_to_cache):\n",
    "        pil_image = self._load_image_pil(image_path_to_cache)\n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(pil_image)\n",
    "        else:\n",
    "            image_tensor = transforms.ToTensor()(pil_image)\n",
    "\n",
    "        if not isinstance(image_tensor, torch.Tensor):\n",
    "            raise TypeError(f\"Transform must output a torch.Tensor. Got {type(image_tensor)}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.image_cache_gpu[image_path_to_cache] = image_tensor.to(self.device, non_blocking=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item_data = self.items_list[idx]\n",
    "        image_path = item_data['image_path']\n",
    "        label_idx = item_data['label_idx']\n",
    "\n",
    "        label_tensor = torch.tensor(self.all_labels_array_source[label_idx], dtype=torch.float32)\n",
    "\n",
    "        if self.enable_gpu_cache and image_path in self.image_cache_gpu:\n",
    "            image_tensor = self.image_cache_gpu[image_path].clone() # Clone to avoid in-place op issues\n",
    "        else: # Not cached or cache miss\n",
    "            if self.enable_gpu_cache and image_path not in self.image_cache_gpu: # Cache miss, load and cache now\n",
    "                 if self.process_rank_for_log == 0 or not self.is_distributed_for_log: # Log only for rank 0 or non-DDP\n",
    "                    print(f\"Rank {self.process_rank_for_log}: Cache miss for {image_path}. Loading on-the-fly & caching.\")\n",
    "                 try:\n",
    "                    self._load_and_cache_to_gpu(image_path)\n",
    "                    image_tensor = self.image_cache_gpu[image_path].clone()\n",
    "                 except Exception as e: # Fallback if caching during __getitem__ fails\n",
    "                    print(f\"Rank {self.process_rank_for_log}: Failed to cache {image_path} during __getitem__: {e}. Loading without cache for this item.\")\n",
    "                    pil_image = self._load_image_pil(image_path)\n",
    "                    image_tensor = self.transform(pil_image) if self.transform else transforms.ToTensor()(pil_image)\n",
    "            else: # GPU caching disabled or not applicable\n",
    "                pil_image = self._load_image_pil(image_path)\n",
    "                image_tensor = self.transform(pil_image) if self.transform else transforms.ToTensor()(pil_image)\n",
    "        return image_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory_for_gpu_caching(num_images, per_image_tensor_shape, current_device_index, rank_for_log=0, is_distributed_for_log=False):\n",
    "    # ... (definition from your DDP script) ...\n",
    "    try:\n",
    "        gpu_caching_viable = False\n",
    "        if torch.cuda.is_available():\n",
    "            elements_per_tensor = np.prod(per_image_tensor_shape)\n",
    "            bytes_per_tensor = elements_per_tensor * 4 # float32\n",
    "            total_estimated_cache_bytes = num_images * bytes_per_tensor\n",
    "            total_estimated_cache_mb = total_estimated_cache_bytes / (1024 * 1024)\n",
    "\n",
    "            props = torch.cuda.get_device_properties(current_device_index)\n",
    "            total_gpu_memory_mb = props.total_memory / (1024 * 1024)\n",
    "            free_mem_bytes, _ = torch.cuda.mem_get_info(current_device_index)\n",
    "            free_memory_mb = free_mem_bytes / (1024*1024)\n",
    "            usable_free_memory_for_cache_mb = free_memory_mb * 0.80 # Target 80% of free\n",
    "\n",
    "            gpu_caching_viable = usable_free_memory_for_cache_mb > total_estimated_cache_mb\n",
    "\n",
    "            if rank_for_log == 0 or not is_distributed_for_log:\n",
    "                print(f\"--- GPU Caching Memory Check (Rank {rank_for_log}, Device {current_device_index}) ---\")\n",
    "                print(f\"Unique images for this dataset instance: {num_images}\")\n",
    "                print(f\"Per image tensor shape: {per_image_tensor_shape}\")\n",
    "                print(f\"Estimated GPU cache size needed: {total_estimated_cache_mb:.2f} MB\")\n",
    "                print(f\"Total VRAM: {total_gpu_memory_mb:.2f} MB, Free VRAM: {free_memory_mb:.2f} MB\")\n",
    "                print(f\"Usable for cache: {usable_free_memory_for_cache_mb:.2f} MB\")\n",
    "                print(f\"Cache Viable: {'YES' if gpu_caching_viable else 'NO'}\")\n",
    "            return gpu_caching_viable\n",
    "        else:\n",
    "            if rank_for_log == 0 or not is_distributed_for_log: print(f\"Rank {rank_for_log}: CUDA not available. GPU caching disabled.\")\n",
    "            return False\n",
    "    except Exception as e_mem:\n",
    "        if rank_for_log == 0 or not is_distributed_for_log: print(f\"Rank {rank_for_log}: Error checking memory for GPU caching: {e_mem}\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device, current_epoch, sampler, is_distributed, rank_process):\n",
    "    # ... (definition from your DDP script) ...\n",
    "    model.train()\n",
    "    if is_distributed and sampler is not None:\n",
    "        sampler.set_epoch(current_epoch)\n",
    "\n",
    "    total_loss_epoch = 0; batch_losses_list = []\n",
    "    pbar_disabled = rank_process != 0 if is_distributed else False\n",
    "    pbar = tqdm(loader, desc=f'Epoch {current_epoch+1} Training', leave=False, disable=pbar_disabled)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(); outputs = model(images); loss = criterion(outputs, labels)\n",
    "        loss.backward(); optimizer.step()\n",
    "        batch_loss_item = loss.item()\n",
    "        total_loss_epoch += batch_loss_item; batch_losses_list.append(batch_loss_item)\n",
    "        if rank_process == 0: pbar.set_postfix({'loss': f'{batch_loss_item:.4f}', 'avg_loss': f'{np.mean(batch_losses_list):.4f}'})\n",
    "    avg_loss_epoch = total_loss_epoch / len(loader) if len(loader) > 0 else 0.0\n",
    "    if is_distributed:\n",
    "        loss_tensor_device = torch.tensor(avg_loss_epoch).to(device)\n",
    "        return reduce_tensor(loss_tensor_device, dist.get_world_size()).item()\n",
    "    return avg_loss_epoch\n",
    "\n",
    "def validate(model, loader, criterion, device, is_distributed, rank_process, world_size_val, target_columns_val):\n",
    "    # ... (definition from your DDP script) ...\n",
    "    model.eval()\n",
    "    total_loss_val_epoch = 0; all_predictions_val_list = []; all_labels_val_list = []\n",
    "    pbar_disabled = rank_process != 0 if is_distributed else False\n",
    "    pbar = tqdm(loader, desc='Validating', leave=False, disable=pbar_disabled)\n",
    "    with torch.no_grad():\n",
    "        for images, labels_batch_val in pbar:\n",
    "            images, labels_batch_val = images.to(device), labels_batch_val.to(device)\n",
    "            outputs = model(images); loss_val = criterion(outputs, labels_batch_val)\n",
    "            total_loss_val_epoch += loss_val.item()\n",
    "            if is_distributed:\n",
    "                outputs_cont = outputs.contiguous(); labels_batch_val_cont = labels_batch_val.contiguous()\n",
    "                pred_list_gathered = [torch.zeros_like(outputs_cont) for _ in range(world_size_val)]\n",
    "                label_list_gathered = [torch.zeros_like(labels_batch_val_cont) for _ in range(world_size_val)]\n",
    "                dist.all_gather(pred_list_gathered, outputs_cont); dist.all_gather(label_list_gathered, labels_batch_val_cont)\n",
    "                if rank_process == 0:\n",
    "                    all_predictions_val_list.extend([p.cpu().numpy() for p in pred_list_gathered])\n",
    "                    all_labels_val_list.extend([l.cpu().numpy() for l in label_list_gathered])\n",
    "            else:\n",
    "                all_predictions_val_list.append(outputs.cpu().numpy()); all_labels_val_list.append(labels_batch_val.cpu().numpy())\n",
    "            if rank_process == 0: pbar.set_postfix({'loss': f'{loss_val.item():.4f}'})\n",
    "    avg_loss_val_epoch = total_loss_val_epoch / len(loader) if len(loader) > 0 else 0.0\n",
    "    percentage_errors_val_agg = {}; predictions_np_val = np.array([]); labels_np_val = np.array([])\n",
    "    if rank_process == 0 and all_predictions_val_list:\n",
    "        predictions_np_val = np.concatenate([arr for arr in all_predictions_val_list if arr.size > 0])\n",
    "        labels_np_val = np.concatenate([arr for arr in all_labels_val_list if arr.size > 0])\n",
    "        if labels_np_val.ndim == 2 and labels_np_val.shape[1] == len(target_columns_val):\n",
    "            for i, col_name in enumerate(target_columns_val):\n",
    "                mae_val = mean_absolute_error(labels_np_val[:, i], predictions_np_val[:, i])\n",
    "                mean_true_val = labels_np_val[:, i].mean()\n",
    "                percentage_errors_val_agg[col_name] = (mae_val / (mean_true_val + 1e-9)) * 100\n",
    "        # ... (handle 1D case if needed) ...\n",
    "    if is_distributed:\n",
    "        loss_val_tensor_device = torch.tensor(avg_loss_val_epoch).to(device)\n",
    "        return reduce_tensor(loss_val_tensor_device, world_size_val).item(), percentage_errors_val_agg, predictions_np_val, labels_np_val\n",
    "    return avg_loss_val_epoch, percentage_errors_val_agg, predictions_np_val, labels_np_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, target_cols_list, per_100g=True):\n",
    "    metrics_list = []\n",
    "    for nutrient_col in target_cols_list:\n",
    "        true_col_suffix = '_true'; pred_col_suffix = '_pred'\n",
    "        base_nutrient_name = nutrient_col # e.g. 'calories_per_100g'\n",
    "        if not per_100g: # For absolute values\n",
    "            # nutrient_col is like 'calories_per_100g', need 'calories'\n",
    "            root_name = nutrient_col.replace('_per_100g', '')\n",
    "            true_col_name = f'{root_name}_abs_true'\n",
    "            pred_col_name = f'{root_name}_abs_pred'\n",
    "        else:\n",
    "            true_col_name = f'{base_nutrient_name}_true'\n",
    "            pred_col_name = f'{base_nutrient_name}_pred'\n",
    "\n",
    "        if true_col_name not in df.columns or pred_col_name not in df.columns:\n",
    "            # print(f\"Rank 0 Warning: Columns {true_col_name} or {pred_col_name} not found for {nutrient_col} in metrics.\")\n",
    "            continue\n",
    "        \n",
    "        valid_idx = ~ (df[true_col_name].isnull() | df[pred_col_name].isnull())\n",
    "        true_vals = df.loc[valid_idx, true_col_name].values\n",
    "        pred_vals = df.loc[valid_idx, pred_col_name].values\n",
    "\n",
    "        if len(true_vals) == 0: continue\n",
    "        mae = mean_absolute_error(true_vals, pred_vals)\n",
    "        rmse = np.sqrt(mean_squared_error(true_vals, pred_vals))\n",
    "        r2 = r2_score(true_vals, pred_vals)\n",
    "        mean_true = np.mean(true_vals); mean_pred = np.mean(pred_vals)\n",
    "        perc_err = (mae / (mean_true + 1e-9)) * 100 if mean_true != 0 else float('inf')\n",
    "        metrics_list.append({\n",
    "            'Nutrient': nutrient_col if per_100g else root_name + \" (abs)\",\n",
    "            'MAE': mae, 'RMSE': rmse, 'R²': r2,\n",
    "            '% Error': perc_err, 'Mean True': mean_true, 'Mean Pred': mean_pred\n",
    "        })\n",
    "    return pd.DataFrame(metrics_list)\n",
    "\n",
    "def show_predictions_with_images_ddp(n_samples, results_df, items_list_for_images, # items_list_for_images is val_items_main_final\n",
    "                                     output_dir, model_name_arg, target_columns_arg, rank_for_log=0):\n",
    "    if rank_for_log != 0: return # Only rank 0 saves plots\n",
    "\n",
    "    actual_n = min(n_samples, len(results_df))\n",
    "    if actual_n == 0:\n",
    "        print(\"Rank 0: No samples for image predictions plot.\"); return\n",
    "\n",
    "    sample_indices_df = np.random.choice(len(results_df), actual_n, replace=False)\n",
    "    ncols = 3; nrows = (actual_n + ncols - 1) // ncols\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 5 * nrows), squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i_ax, ax_plot in enumerate(axes):\n",
    "        if i_ax >= actual_n: ax_plot.axis('off'); continue\n",
    "        df_row_idx = sample_indices_df[i_ax] # Index for results_df\n",
    "\n",
    "        # results_df.iloc[df_row_idx] corresponds to items_list_for_images[df_row_idx]\n",
    "        item_info_for_plot = items_list_for_images[df_row_idx]\n",
    "        dish_id_plot = item_info_for_plot['dish_id']\n",
    "        image_path_plot = item_info_for_plot['image_path']\n",
    "\n",
    "        if not os.path.exists(image_path_plot):\n",
    "            ax_plot.text(0.5,0.5, f\"Img not found:\\n{os.path.basename(image_path_plot)}\", ha='center'); ax_plot.axis('off'); continue\n",
    "        \n",
    "        try: img = Image.open(image_path_plot)\n",
    "        except Exception as e_img:\n",
    "            ax_plot.text(0.5,0.5, f\"Error opening:\\n{os.path.basename(image_path_plot)}\\n{e_img}\", ha='center'); ax_plot.axis('off'); continue\n",
    "\n",
    "        ax_plot.imshow(img); ax_plot.axis('off')\n",
    "        pred_txt, true_txt = \"Pred:\\n\", \"Actual (Err %):\\n\"\n",
    "        for nutrient_col in target_columns_arg:\n",
    "            pred_val = results_df.iloc[df_row_idx][f'{nutrient_col}_pred']\n",
    "            true_val = results_df.iloc[df_row_idx][f'{nutrient_col}_true']\n",
    "            err_pct = abs(pred_val - true_val) / (abs(true_val) + 1e-9) * 100 if true_val != 0 else float('inf')\n",
    "            disp_name = nutrient_col.split('_')[0].capitalize()[:3]\n",
    "            pred_txt += f\"{disp_name}: {pred_val:.0f}\\n\"\n",
    "            true_txt += f\"{disp_name}: {true_val:.0f} ({err_pct:.1f}%)\\n\"\n",
    "        \n",
    "        ax_plot.text(0.02, 0.98, pred_txt, transform=ax_plot.transAxes, va='top', bbox=dict(boxstyle='round', fc='lightblue', alpha=0.8), fontsize=8)\n",
    "        ax_plot.text(0.98, 0.98, true_txt, transform=ax_plot.transAxes, va='top', ha='right', bbox=dict(boxstyle='round', fc='lightgreen', alpha=0.8), fontsize=8)\n",
    "        ax_plot.set_title(f\"Dish: {dish_id_plot}\\nView: {os.path.basename(image_path_plot)}\", fontsize=9)\n",
    "\n",
    "    for j in range(actual_n, len(axes)): fig.delaxes(axes[j])\n",
    "    plt.tight_layout(rect=[0,0,1,0.96]); plt.suptitle(f'Sample Predictions ({model_name_arg})', fontsize=14)\n",
    "    plot_path = os.path.join(output_dir, f\"plot_sample_preds_{model_name_arg}.png\")\n",
    "    plt.savefig(plot_path); print(f\"Rank 0: Sample predictions plot saved: {plot_path}\"); plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ARGS, RANK, WORLD_SIZE, DEVICE, IS_DISTRIBUTED = parse_arguments()\n",
    "\n",
    "    if RANK == 0:\n",
    "        os.makedirs(ARGS.output_dir, exist_ok=True)\n",
    "        print(f\"Running with arguments: {ARGS}\")\n",
    "        print(f\"Process Rank: {RANK}, World Size: {WORLD_SIZE}, Device: {PROCESS_DEVICE}, Distributed: {IS_DISTRIBUTED}\")\n",
    "\n",
    "    # --- Configuration from ARGS ---\n",
    "    LOCAL_BASE_DIR_MAIN = ARGS.base_dir\n",
    "    IMAGERY_BASE_DIR_MAIN = os.path.join(LOCAL_BASE_DIR_MAIN, \"imagery\")\n",
    "    OVERHEAD_IMAGERY_DIR_MAIN = os.path.join(IMAGERY_BASE_DIR_MAIN, \"realsense_overhead\")\n",
    "    SIDE_ANGLES_IMAGERY_DIR_MAIN = os.path.join(IMAGERY_BASE_DIR_MAIN, \"side_angles\")\n",
    "    SIDE_ANGLES_SUBDIR_NAME_MAIN = \"extracted_frames\"\n",
    "    METADATA_FILE_CAFE1_MAIN = os.path.join(LOCAL_BASE_DIR_MAIN, \"metadata/dish_metadata_cafe1.csv\")\n",
    "    METADATA_FILE_CAFE2_MAIN = os.path.join(LOCAL_BASE_DIR_MAIN, \"metadata/dish_metadata_cafe2.csv\")\n",
    "    RGB_IMAGE_FILENAME_MAIN = \"rgb.png\" # For overhead\n",
    "    TARGET_COLUMNS_MAIN = ['calories_per_100g', 'fat_per_100g', 'carbs_per_100g', 'protein_per_100g']\n",
    "\n",
    "    # --- Data Loading and Preprocessing (Rank 0 prepares, then broadcasts) ---\n",
    "    train_items_main_final, val_items_main_final, all_labels_main_array, filtered_metadata_for_eval_main = None, None, None, None\n",
    "\n",
    "    if RANK == 0:\n",
    "        print(\"Rank 0: Preparing and loading dataset metadata...\")\n",
    "        # Path checks\n",
    "        paths_to_check = [LOCAL_BASE_DIR_MAIN, OVERHEAD_IMAGERY_DIR_MAIN, METADATA_FILE_CAFE1_MAIN, METADATA_FILE_CAFE2_MAIN]\n",
    "        if ARGS.include_side_angles:\n",
    "            paths_to_check.append(SIDE_ANGLES_IMAGERY_DIR_MAIN)\n",
    "        for p_main in paths_to_check:\n",
    "            if not os.path.exists(p_main):\n",
    "                print(f\"ERROR (Rank 0): Path not found: {p_main}. Exiting.\")\n",
    "                # Signal other processes to exit if in DDP\n",
    "                if IS_DISTRIBUTED: dist.barrier(); cleanup_distributed()\n",
    "                sys.exit(1)\n",
    "\n",
    "        dish_df_cafe1_main = parse_nutrition_csv(METADATA_FILE_CAFE1_MAIN)\n",
    "        dish_df_cafe2_main = parse_nutrition_csv(METADATA_FILE_CAFE2_MAIN)\n",
    "        raw_dish_metadata_df = pd.concat([dish_df_cafe1_main, dish_df_cafe2_main], ignore_index=True)\n",
    "        raw_dish_metadata_df = raw_dish_metadata_df.replace([np.inf, -np.inf], np.nan)\n",
    "        all_dish_metadata_df_main = raw_dish_metadata_df.dropna(subset=TARGET_COLUMNS_MAIN + ['dish_id', 'weight'])\n",
    "        all_dish_metadata_df_main = all_dish_metadata_df_main.set_index('dish_id')\n",
    "\n",
    "        dataset_items_rank0 = []\n",
    "        all_labels_list_rank0 = []\n",
    "        dish_id_to_label_idx_rank0 = {}\n",
    "\n",
    "        for dish_id, row_data in tqdm(all_dish_metadata_df_main.iterrows(), total=len(all_dish_metadata_df_main), desc=\"Rank 0: Processing dishes\"):\n",
    "            has_any_image_for_dish = False\n",
    "            if dish_id not in dish_id_to_label_idx_rank0:\n",
    "                dish_id_to_label_idx_rank0[dish_id] = len(all_labels_list_rank0)\n",
    "                all_labels_list_rank0.append(row_data[TARGET_COLUMNS_MAIN].values.astype(np.float32))\n",
    "            label_idx = dish_id_to_label_idx_rank0[dish_id]\n",
    "\n",
    "            overhead_img_path = os.path.join(OVERHEAD_IMAGERY_DIR_MAIN, dish_id, RGB_IMAGE_FILENAME_MAIN)\n",
    "            if os.path.exists(overhead_img_path):\n",
    "                dataset_items_rank0.append({'dish_id': dish_id, 'label_idx': label_idx, 'image_type': 'overhead', 'image_path': overhead_img_path})\n",
    "                has_any_image_for_dish = True\n",
    "            \n",
    "            if ARGS.include_side_angles:\n",
    "                dish_side_angle_base = os.path.join(SIDE_ANGLES_IMAGERY_DIR_MAIN, dish_id, SIDE_ANGLES_SUBDIR_NAME_MAIN)\n",
    "                if os.path.isdir(dish_side_angle_base):\n",
    "                    available_frames = [os.path.join(dish_side_angle_base, f) for f in os.listdir(dish_side_angle_base) if f.startswith(\"camera_\") and f.endswith(\".png\")]\n",
    "                    if available_frames:\n",
    "                        has_any_image_for_dish = True\n",
    "                        if ARGS.num_side_angles_per_dish > 0 and len(available_frames) > ARGS.num_side_angles_per_dish:\n",
    "                            selected_frames = np.random.choice(available_frames, ARGS.num_side_angles_per_dish, replace=False).tolist()\n",
    "                        else:\n",
    "                            selected_frames = available_frames\n",
    "                        for frame_path in selected_frames:\n",
    "                            dataset_items_rank0.append({'dish_id': dish_id, 'label_idx': label_idx, 'image_type': 'side_angle', 'image_path': frame_path})\n",
    "            \n",
    "            # If a dish has no images, its label might be unused. This is generally okay.\n",
    "        \n",
    "        if not dataset_items_rank0:\n",
    "            print(\"ERROR (Rank 0): No dataset items found after scanning for images. Check paths and data. Exiting.\")\n",
    "            if IS_DISTRIBUTED: dist.barrier(); cleanup_distributed()\n",
    "            sys.exit(1)\n",
    "\n",
    "        all_labels_main_array = np.array(all_labels_list_rank0, dtype=np.float32)\n",
    "\n",
    "        unique_dish_ids_in_dataset = sorted(list(set(item['dish_id'] for item in dataset_items_rank0)))\n",
    "        if len(unique_dish_ids_in_dataset) < 2:\n",
    "            print(\"ERROR (Rank 0): Not enough unique dishes for train/test split. Exiting.\")\n",
    "            if IS_DISTRIBUTED: dist.barrier(); cleanup_distributed()\n",
    "            sys.exit(1)\n",
    "            \n",
    "        train_dish_ids_split, val_dish_ids_split = train_test_split(unique_dish_ids_in_dataset, test_size=0.2, random_state=42)\n",
    "        \n",
    "        train_items_main_final = [item for item in dataset_items_rank0 if item['dish_id'] in train_dish_ids_split]\n",
    "        val_items_main_final = [item for item in dataset_items_rank0 if item['dish_id'] in val_dish_ids_split]\n",
    "\n",
    "        # filtered_metadata_for_eval_main (for evaluation reports)\n",
    "        final_dish_ids_in_eval_set = sorted(list(set(item['dish_id'] for item in val_items_main_final))) # Use val_items for eval metadata\n",
    "        filtered_metadata_for_eval_main = all_dish_metadata_df_main.loc[all_dish_metadata_df_main.index.isin(final_dish_ids_in_eval_set)].copy()\n",
    "        if filtered_metadata_for_eval_main.index.name == 'dish_id':\n",
    "            filtered_metadata_for_eval_main.reset_index(inplace=True) # Ensure 'dish_id' is a column\n",
    "\n",
    "        print(f\"Rank 0: Total dataset items (views): {len(dataset_items_rank0)}\")\n",
    "        image_type_counts_rank0 = Counter(item['image_type'] for item in dataset_items_rank0)\n",
    "        print(f\"Rank 0: Image type distribution: {image_type_counts_rank0}\")\n",
    "        print(f\"Rank 0: Train items: {len(train_items_main_final)}, Val items: {len(val_items_main_final)}\")\n",
    "        print(f\"Rank 0: Unique labels: {len(all_labels_main_array)}\")\n",
    "        if not filtered_metadata_for_eval_main.empty:\n",
    "            print(f\"Rank 0: Metadata for eval contains {len(filtered_metadata_for_eval_main)} unique dishes from validation set.\")\n",
    "\n",
    "    # Broadcast data from Rank 0 to all other ranks\n",
    "    broadcast_data_list = [None] * 4 # For train_items, val_items, all_labels, filtered_eval_meta\n",
    "    if IS_DISTRIBUTED:\n",
    "        if RANK == 0:\n",
    "            broadcast_data_list[0] = train_items_main_final\n",
    "            broadcast_data_list[1] = val_items_main_final\n",
    "            broadcast_data_list[2] = all_labels_main_array\n",
    "            broadcast_data_list[3] = filtered_metadata_for_eval_main\n",
    "        \n",
    "        dist.broadcast_object_list(broadcast_data_list, src=0)\n",
    "        \n",
    "        if RANK != 0: # Assign received data on other ranks\n",
    "            train_items_main_final = broadcast_data_list[0]\n",
    "            val_items_main_final = broadcast_data_list[1]\n",
    "            all_labels_main_array = broadcast_data_list[2]\n",
    "            filtered_metadata_for_eval_main = broadcast_data_list[3]\n",
    "    \n",
    "    # Verify data received on all ranks\n",
    "    data_valid = True\n",
    "    if train_items_main_final is None or val_items_main_final is None or \\\n",
    "       all_labels_main_array is None or (RANK == 0 and filtered_metadata_for_eval_main is None):\n",
    "        data_valid = False\n",
    "        print(f\"Rank {RANK}: ERROR - Data not properly received/initialized after broadcast.\")\n",
    "\n",
    "    if IS_DISTRIBUTED: # Sync point to check validity across all ranks\n",
    "        valid_tensor = torch.tensor([1.0 if data_valid else 0.0], device=DEVICE)\n",
    "        dist.all_reduce(valid_tensor, op=dist.ReduceOp.MIN) # If any rank failed, all_reduce results in 0\n",
    "        if valid_tensor.item() == 0.0:\n",
    "            if RANK == 0: print(\"CRITICAL ERROR: Data loading/broadcasting failed on one or more ranks. Exiting.\")\n",
    "            cleanup_distributed()\n",
    "            sys.exit(1)\n",
    "    elif not data_valid: # Single process mode failure\n",
    "         print(\"CRITICAL ERROR: Data loading failed in non-distributed mode. Exiting.\")\n",
    "         sys.exit(1)\n",
    "\n",
    "    if RANK == 0 and not IS_DISTRIBUTED: # Print summary for non-DDP if it was rank 0 only\n",
    "        print(f\"Dataset items (views): {len(train_items_main_final) + len(val_items_main_final)}\")\n",
    "        print(f\"Train items: {len(train_items_main_final)}, Val items: {len(val_items_main_final)}\")\n",
    "\n",
    "\n",
    "    # --- Transforms ---\n",
    "    train_transform_main = transforms.Compose([\n",
    "        transforms.Resize((256, 256)), transforms.RandomCrop(224), transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1), transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transform_main = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # --- GPU Caching Check & DataLoader Params ---\n",
    "    attempt_gpu_cache_train, attempt_gpu_cache_val = False, False\n",
    "    _dummy_pil_train = Image.new(\"RGB\", (256, 256)); _tensor_shape_train = train_transform_main(_dummy_pil_train).shape\n",
    "    _dummy_pil_val = Image.new(\"RGB\", (224, 224));   _tensor_shape_val = val_transform_main(_dummy_pil_val).shape\n",
    "    \n",
    "    num_unique_train_images = len(set(item['image_path'] for item in train_items_main_final))\n",
    "    num_unique_val_images = len(set(item['image_path'] for item in val_items_main_final))\n",
    "\n",
    "    if ARGS.enable_gpu_caching:\n",
    "        can_cache_train_rank = check_memory_for_gpu_caching(num_unique_train_images, _tensor_shape_train, DEVICE.index if DEVICE.type == 'cuda' else 0, RANK, IS_DISTRIBUTED)\n",
    "        can_cache_val_rank = check_memory_for_gpu_caching(num_unique_val_images, _tensor_shape_val, DEVICE.index if DEVICE.type == 'cuda' else 0, RANK, IS_DISTRIBUTED)\n",
    "        \n",
    "        if IS_DISTRIBUTED:\n",
    "            # All ranks must agree to cache (or not cache) for simplicity, based on min capability\n",
    "            train_cache_tensor = torch.tensor(1.0 if can_cache_train_rank else 0.0, device=DEVICE)\n",
    "            val_cache_tensor = torch.tensor(1.0 if can_cache_val_rank else 0.0, device=DEVICE)\n",
    "            dist.all_reduce(train_cache_tensor, op=dist.ReduceOp.MIN)\n",
    "            dist.all_reduce(val_cache_tensor, op=dist.ReduceOp.MIN)\n",
    "            attempt_gpu_cache_train = train_cache_tensor.item() == 1.0\n",
    "            attempt_gpu_cache_val = val_cache_tensor.item() == 1.0\n",
    "        else:\n",
    "            attempt_gpu_cache_train = can_cache_train_rank\n",
    "            attempt_gpu_cache_val = can_cache_val_rank\n",
    "    \n",
    "    actual_num_workers_main = ARGS.num_workers\n",
    "    # If any dataset is cached, force num_workers to 0 for all DataLoaders on this rank\n",
    "    if (attempt_gpu_cache_train or attempt_gpu_cache_val):\n",
    "        if ARGS.num_workers > 0 and (RANK == 0 or not IS_DISTRIBUTED):\n",
    "            print(f\"Rank {RANK}: GPU Caching active for at least one dataset. Forcing num_workers from {ARGS.num_workers} to 0.\")\n",
    "        actual_num_workers_main = 0\n",
    "    \n",
    "    pin_memory_main = not (attempt_gpu_cache_train or attempt_gpu_cache_val) # Pin if not caching to GPU directly\n",
    "\n",
    "    if RANK == 0:\n",
    "        print(f\"Final DataLoader settings: GPU Caching Train: {attempt_gpu_cache_train}, Val: {attempt_gpu_cache_val}\")\n",
    "        print(f\"Num Workers: {actual_num_workers_main}, Pin Memory: {pin_memory_main}\")\n",
    "\n",
    "    # --- Datasets and DataLoaders ---\n",
    "    train_dataset_main = NutritionDataset(train_items_main_final, all_labels_main_array, train_transform_main,\n",
    "                                          attempt_gpu_cache_train, DEVICE, RANK, IS_DISTRIBUTED)\n",
    "    val_dataset_main = NutritionDataset(val_items_main_final, all_labels_main_array, val_transform_main,\n",
    "                                        attempt_gpu_cache_val, DEVICE, RANK, IS_DISTRIBUTED)\n",
    "\n",
    "    train_sampler_main = DistributedSampler(train_dataset_main, num_replicas=WORLD_SIZE, rank=RANK, shuffle=True) if IS_DISTRIBUTED else None\n",
    "    val_sampler_main = DistributedSampler(val_dataset_main, num_replicas=WORLD_SIZE, rank=RANK, shuffle=False, drop_last=False) if IS_DISTRIBUTED else None # drop_last=False for full eval\n",
    "\n",
    "    train_loader_main = DataLoader(train_dataset_main, batch_size=ARGS.batch_size, sampler=train_sampler_main,\n",
    "                                   num_workers=actual_num_workers_main, shuffle=(train_sampler_main is None),\n",
    "                                   pin_memory=pin_memory_main)\n",
    "    val_loader_main = DataLoader(val_dataset_main, batch_size=ARGS.batch_size, sampler=val_sampler_main,\n",
    "                                 num_workers=actual_num_workers_main, shuffle=False,\n",
    "                                 pin_memory=pin_memory_main)\n",
    "    if RANK == 0:\n",
    "        print(f\"Training views: {len(train_dataset_main)}, Validation views: {len(val_dataset_main)}\")\n",
    "\n",
    "    # --- Model, Criterion, Optimizer, Scheduler (largely same as DDP script) ---\n",
    "    model_configs_main = {\n",
    "        'SimpleConvNet': SimpleConvNet(num_outputs=len(TARGET_COLUMNS_MAIN)),\n",
    "        'DeepConvNet': DeepConvNet(num_outputs=len(TARGET_COLUMNS_MAIN)),\n",
    "        'MobileNetLike': MobileNetLike(num_outputs=len(TARGET_COLUMNS_MAIN)),\n",
    "        'ResNetFromScratch': ResNetFromScratch(num_outputs=len(TARGET_COLUMNS_MAIN), use_pretrained=False),\n",
    "        'ResNetPretrained': ResNetFromScratch(num_outputs=len(TARGET_COLUMNS_MAIN), use_pretrained=True)\n",
    "    }\n",
    "    model_main = model_configs_main[ARGS.model_name].to(DEVICE)\n",
    "    if IS_DISTRIBUTED:\n",
    "        model_main = DDP(model_main, device_ids=[DEVICE.index] if DEVICE.type == 'cuda' else None,\n",
    "                         output_device=DEVICE.index if DEVICE.type == 'cuda' else None,\n",
    "                         find_unused_parameters=False) # Set to True if you have conditional paths in forward not always used\n",
    "    if RANK == 0: print(f\"Model: {ARGS.model_name}, Total params: {sum(p.numel() for p in model_main.parameters()):,}\")\n",
    "    criterion_main = nn.L1Loss()\n",
    "    optimizer_main = optim.Adam(model_main.parameters(), lr=ARGS.lr)\n",
    "    scheduler_main = optim.lr_scheduler.ReduceLROnPlateau(optimizer_main, 'min', patience=10, factor=0.5, verbose=(RANK==0))\n",
    "\n",
    "\n",
    "    # --- Training Loop (largely same as DDP script) ---\n",
    "    best_val_loss_main = float('inf')\n",
    "    history_main = {'train_loss': [], 'val_loss': [], 'percentage_errors': [], 'lr': []}\n",
    "    MODEL_SAVE_PATH_MAIN = os.path.join(ARGS.output_dir, f'best_nutrition_model_{ARGS.model_name}.pth')\n",
    "    HISTORY_SAVE_PATH_MAIN = os.path.join(ARGS.output_dir, f'training_history_{ARGS.model_name}.pkl')\n",
    "\n",
    "    if train_loader_main and val_loader_main:\n",
    "        # ... (training loop from your DDP script, ensure it uses main variables) ...\n",
    "        loop_current_epoch = 0\n",
    "        try:\n",
    "            for epoch_iter in range(ARGS.epochs):\n",
    "                loop_current_epoch = epoch_iter; epoch_start_time_main = time.time()\n",
    "                current_lr_main = optimizer_main.param_groups[0]['lr']\n",
    "                if RANK == 0: print(f\"\\nEPOCH {epoch_iter+1}/{ARGS.epochs} | LR: {current_lr_main:.6f}\")\n",
    "\n",
    "                train_loss_main = train_epoch(model_main, train_loader_main, criterion_main, optimizer_main, DEVICE, epoch_iter, train_sampler_main, IS_DISTRIBUTED, RANK)\n",
    "                val_loss_main, percentage_errors_main, _, _ = validate(model_main, val_loader_main, criterion_main, DEVICE, IS_DISTRIBUTED, RANK, WORLD_SIZE, TARGET_COLUMNS_MAIN)\n",
    "                scheduler_main.step(val_loss_main)\n",
    "\n",
    "                if RANK == 0:\n",
    "                    history_main['train_loss'].append(train_loss_main)\n",
    "                    history_main['val_loss'].append(val_loss_main)\n",
    "                    history_main['percentage_errors'].append(percentage_errors_main)\n",
    "                    history_main['lr'].append(current_lr_main)\n",
    "                    epoch_time_main = time.time() - epoch_start_time_main\n",
    "                    print(f\"Epoch {epoch_iter+1} Results (Rank 0): Train Loss: {train_loss_main:.4f}, Val Loss: {val_loss_main:.4f}, Time: {epoch_time_main:.2f}s\")\n",
    "                    if percentage_errors_main:\n",
    "                        print(\"Val Percentage Errors (per 100g, Rank 0):\")\n",
    "                        for nutrient, error in percentage_errors_main.items(): print(f\"  {nutrient}: {error:.2f}%\")\n",
    "                    if val_loss_main < best_val_loss_main:\n",
    "                        best_val_loss_main = val_loss_main\n",
    "                        torch.save({\n",
    "                            'epoch': epoch_iter,\n",
    "                            'model_state_dict': model_main.module.state_dict() if IS_DISTRIBUTED else model_main.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer_main.state_dict(), 'scheduler_state_dict': scheduler_main.state_dict(),\n",
    "                            'best_val_loss': best_val_loss_main, 'model_name': ARGS.model_name, 'args': vars(ARGS),\n",
    "                            'target_columns': TARGET_COLUMNS_MAIN # Save target columns\n",
    "                        }, MODEL_SAVE_PATH_MAIN)\n",
    "                        print(f\"✓ NEW BEST MODEL SAVED to {MODEL_SAVE_PATH_MAIN}\")\n",
    "                if IS_DISTRIBUTED: dist.barrier()\n",
    "        except KeyboardInterrupt:\n",
    "            if RANK == 0: print(f\"\\nTraining interrupted. Completed {loop_current_epoch}/{ARGS.epochs} epochs.\")\n",
    "        except Exception as e_main:\n",
    "            print(f\"Rank {RANK} Error during training: {e_main}\"); import traceback; traceback.print_exc()\n",
    "        finally:\n",
    "            if RANK == 0 and history_main['train_loss']:\n",
    "                print(f\"\\nTraining Summary (Rank 0) - {ARGS.model_name}\"); print(f\"Best Val Loss: {best_val_loss_main:.4f}\")\n",
    "                with open(HISTORY_SAVE_PATH_MAIN, 'wb') as f_hist: pickle.dump(history_main, f_hist)\n",
    "                print(f\"Training history saved to: {HISTORY_SAVE_PATH_MAIN}\")\n",
    "\n",
    "    # --- Plotting and Final Evaluation (Rank 0 only) ---\n",
    "    if RANK == 0:\n",
    "        # Load history for plotting\n",
    "        loaded_history_main = None\n",
    "        if os.path.exists(HISTORY_SAVE_PATH_MAIN):\n",
    "            try:\n",
    "                with open(HISTORY_SAVE_PATH_MAIN, 'rb') as f: loaded_history_main = pickle.load(f)\n",
    "            except Exception as e: print(f\"Rank 0: Could not load history {HISTORY_SAVE_PATH_MAIN}: {e}\")\n",
    "\n",
    "        if loaded_history_main and loaded_history_main.get('train_loss') and ARGS.save_plots:\n",
    "            # ... (Plotting loss/errors from your DDP script, adapted for loaded_history_main)\n",
    "            fig_loss, (ax1_loss, ax2_loss) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            ax1_loss.plot(loaded_history_main['train_loss'], label='Train Loss')\n",
    "            ax1_loss.plot(loaded_history_main['val_loss'], label='Val Loss')\n",
    "            ax1_loss.set_xlabel('Epoch'); ax1_loss.set_ylabel('Loss'); ax1_loss.set_title('Loss'); ax1_loss.legend(); ax1_loss.grid(True)\n",
    "            if loaded_history_main.get('percentage_errors') and loaded_history_main['percentage_errors']:\n",
    "                percentage_df_main = pd.DataFrame(loaded_history_main['percentage_errors'])\n",
    "                if not percentage_df_main.empty:\n",
    "                    for col_plot in percentage_df_main.columns: ax2_loss.plot(percentage_df_main[col_plot], label=col_plot)\n",
    "                    ax2_loss.set_xlabel('Epoch'); ax2_loss.set_ylabel('Percentage Error (%)'); ax2_loss.set_title('Val Pct Errors'); ax2_loss.legend(); ax2_loss.grid(True)\n",
    "            plt.tight_layout(); plt.savefig(os.path.join(ARGS.output_dir, f\"plot_loss_errors_{ARGS.model_name}.png\")); plt.close(fig_loss)\n",
    "            print(f\"Rank 0: Loss/Error plot saved for {ARGS.model_name}\")\n",
    "\n",
    "\n",
    "        # Evaluation with the best model\n",
    "        results_df_eval_main = pd.DataFrame()\n",
    "        if os.path.exists(MODEL_SAVE_PATH_MAIN) and val_loader_main is not None: # val_loader_main implies val_dataset_main exists\n",
    "            print(f\"\\nRank 0: Evaluating best model from {MODEL_SAVE_PATH_MAIN}...\")\n",
    "            try:\n",
    "                checkpoint_main = torch.load(MODEL_SAVE_PATH_MAIN, map_location=DEVICE)\n",
    "                eval_model_main = model_configs_main[ARGS.model_name].to(DEVICE) # Re-init model structure\n",
    "                \n",
    "                state_dict = checkpoint_main['model_state_dict']\n",
    "                # Adjust for DDP saved model if current mode is non-DDP for eval, or vice-versa\n",
    "                # This logic assumes eval is done on a single GPU (non-DDP) on Rank 0\n",
    "                if IS_DISTRIBUTED and not list(state_dict.keys())[0].startswith('module.'): # Model saved non-DDP, current DDP\n",
    "                     #This case should not happen if saving from DDP correctly\n",
    "                     pass\n",
    "                elif (not IS_DISTRIBUTED or WORLD_SIZE == 1) and list(state_dict.keys())[0].startswith('module.'): # Model saved DDP, current non-DDP\n",
    "                    from collections import OrderedDict\n",
    "                    new_state_dict = OrderedDict()\n",
    "                    for k, v in state_dict.items(): new_state_dict[k[7:]] = v # remove `module.`\n",
    "                    state_dict = new_state_dict\n",
    "                eval_model_main.load_state_dict(state_dict)\n",
    "                eval_model_main.eval()\n",
    "\n",
    "                # Create a new DataLoader for rank 0 specific evaluation\n",
    "                # Uses val_items_main_final which was broadcasted, and all_labels_main_array\n",
    "                val_dataset_eval_rank0 = NutritionDataset(\n",
    "                    val_items_main_final, all_labels_main_array, val_transform_main,\n",
    "                    attempt_gpu_cache_val, DEVICE, RANK, False # is_distributed=False for this specific instance\n",
    "                )\n",
    "                val_loader_eval_rank0 = DataLoader(val_dataset_eval_rank0, batch_size=ARGS.batch_size, shuffle=False,\n",
    "                                                   num_workers=actual_num_workers_main, pin_memory=pin_memory_main)\n",
    "\n",
    "                # Validate on rank 0 using the full validation set\n",
    "                _, eval_perc_errors, eval_preds_np, eval_labels_np = validate(\n",
    "                    eval_model_main, val_loader_eval_rank0, criterion_main, DEVICE,\n",
    "                    False, RANK, 1, TARGET_COLUMNS_MAIN # is_distributed=False, world_size=1 for this eval\n",
    "                )\n",
    "\n",
    "                if eval_perc_errors:\n",
    "                    print(f\"Rank 0: Best Model ({ARGS.model_name}) Validation Percentage Errors:\")\n",
    "                    for n, e in eval_perc_errors.items(): print(f\"  {n}: {e:.2f}%\")\n",
    "\n",
    "                if eval_preds_np.size > 0 :\n",
    "                    num_eval_samples = len(eval_preds_np)\n",
    "                    # Ensure val_items_main_final is sliced if drop_last was True during training val\n",
    "                    # Here, val_loader_eval_rank0 ensures we get preds for all items in val_dataset_eval_rank0\n",
    "                    eval_item_details_df = val_items_main_final[:num_eval_samples]\n",
    "\n",
    "                    all_dish_ids_eval_df = [item['dish_id'] for item in eval_item_details_df]\n",
    "                    \n",
    "                    # Use filtered_metadata_for_eval_main (already broadcasted)\n",
    "                    weight_map_eval_df = pd.Series(filtered_metadata_for_eval_main.weight.values, index=filtered_metadata_for_eval_main.dish_id).to_dict()\n",
    "                    all_weights_eval_df = [weight_map_eval_df.get(did, np.nan) for did in all_dish_ids_eval_df]\n",
    "\n",
    "                    results_df_eval_main = pd.DataFrame({\n",
    "                        'dish_id': all_dish_ids_eval_df,\n",
    "                        'weight': all_weights_eval_df\n",
    "                    })\n",
    "                    for i_col, col_name_target in enumerate(TARGET_COLUMNS_MAIN):\n",
    "                        results_df_eval_main[f'{col_name_target}_pred'] = eval_preds_np[:, i_col]\n",
    "                        results_df_eval_main[f'{col_name_target}_true'] = eval_labels_np[:, i_col]\n",
    "                    \n",
    "                    # Add absolute values\n",
    "                    for nutrient_root in ['calories', 'fat', 'carbs', 'protein']:\n",
    "                        nutrient_col_100g = next((tc for tc in TARGET_COLUMNS_MAIN if tc.startswith(nutrient_root)), None)\n",
    "                        if nutrient_col_100g and f'{nutrient_col_100g}_pred' in results_df_eval_main.columns and 'weight' in results_df_eval_main.columns:\n",
    "                            results_df_eval_main[f'{nutrient_root}_abs_pred'] = results_df_eval_main[f'{nutrient_col_100g}_pred'] * results_df_eval_main['weight'] / 100\n",
    "                            results_df_eval_main[f'{nutrient_root}_abs_true'] = results_df_eval_main[f'{nutrient_col_100g}_true'] * results_df_eval_main['weight'] / 100\n",
    "                    \n",
    "                    print(f\"Rank 0: Evaluation predictions completed for {len(results_df_eval_main)} views.\")\n",
    "                    \n",
    "                    # --- Calculate and Print Metrics ---\n",
    "                    print(\"\\nRank 0:\" + \"=\"*30 + f\" METRICS - {ARGS.model_name} (Per 100g) \" + \"=\"*30)\n",
    "                    metrics_df_100g = calculate_metrics(results_df_eval_main, TARGET_COLUMNS_MAIN, per_100g=True)\n",
    "                    if not metrics_df_100g.empty: print(metrics_df_100g.to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "                    print(\"\\nRank 0:\" + \"=\"*25 + \" METRICS - ABSOLUTE (using ground truth weight) \" + \"=\"*25)\n",
    "                    metrics_df_abs = calculate_metrics(results_df_eval_main, TARGET_COLUMNS_MAIN, per_100g=False) # Uses root name logic in calculate_metrics\n",
    "                    if not metrics_df_abs.empty: print(metrics_df_abs.to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "\n",
    "                    # --- Plotting Detailed Evaluation (Preds vs Actual, Error Dist) ---\n",
    "                    if ARGS.save_plots and not results_df_eval_main.empty:\n",
    "                        num_targets_plot = len(TARGET_COLUMNS_MAIN)\n",
    "                        ncols_plot = 2\n",
    "                        # Predictions vs Actual\n",
    "                        nrows_pvsa = (num_targets_plot + ncols_plot - 1) // ncols_plot\n",
    "                        fig_pvsa, axes_pvsa = plt.subplots(nrows_pvsa, ncols_plot, figsize=(7 * ncols_plot, 6 * nrows_pvsa), squeeze=False)\n",
    "                        axes_pvsa = axes_pvsa.flatten()\n",
    "                        for i, nutrient_key in enumerate(TARGET_COLUMNS_MAIN):\n",
    "                            ax = axes_pvsa[i]\n",
    "                            # ... (copy plotting logic for PvA from single-GPU, using results_df_eval_main, nutrient_key) ...\n",
    "                            true_col, pred_col = f'{nutrient_key}_true', f'{nutrient_key}_pred'\n",
    "                            if true_col not in results_df_eval_main.columns or pred_col not in results_df_eval_main.columns: continue\n",
    "                            x_data, y_data = results_df_eval_main[true_col].values, results_df_eval_main[pred_col].values\n",
    "                            valid = ~ (np.isnan(x_data) | np.isnan(y_data))\n",
    "                            x_plot, y_plot = x_data[valid], y_data[valid]\n",
    "                            if len(x_plot) == 0: continue\n",
    "                            ax.scatter(x_plot, y_plot, alpha=0.5, s=30, edgecolors='k', linewidth=0.5)\n",
    "                            min_val_plot, max_val_plot = min(x_plot.min(), y_plot.min()), max(x_plot.max(), y_plot.max())\n",
    "                            ax.plot([min_val_plot, max_val_plot], [min_val_plot, max_val_plot], 'r--', lw=2)\n",
    "                            r2_plot = r2_score(x_plot, y_plot)\n",
    "                            display_name = nutrient_key.replace('_per_100g', '').replace('_', ' ').capitalize()\n",
    "                            ax.set_xlabel(f'True {display_name}'); ax.set_ylabel(f'Pred {display_name}')\n",
    "                            ax.set_title(f'{display_name} (R²={r2_plot:.3f})'); ax.grid(True, alpha=0.3)\n",
    "\n",
    "                        for j_plot in range(num_targets_plot, len(axes_pvsa)): fig_pvsa.delaxes(axes_pvsa[j_plot])\n",
    "                        plt.tight_layout(rect=[0,0,1,0.96]); fig_pvsa.suptitle(f'Predictions vs True ({ARGS.model_name}, per 100g)', fontsize=16)\n",
    "                        pvsa_path = os.path.join(ARGS.output_dir, f\"plot_preds_vs_actual_{ARGS.model_name}.png\")\n",
    "                        plt.savefig(pvsa_path); print(f\"Rank 0: PvA plot saved: {pvsa_path}\"); plt.close(fig_pvsa)\n",
    "\n",
    "                        # Error Distribution Plot (copy from single GPU, adapt for results_df_eval_main)\n",
    "\n",
    "                    # --- Plotting Sample Predictions with Images ---\n",
    "                    if ARGS.save_plots and len(results_df_eval_main) >= 6:\n",
    "                         show_predictions_with_images_ddp(6, results_df_eval_main, val_items_main_final,\n",
    "                                                         ARGS.output_dir, ARGS.model_name, TARGET_COLUMNS_MAIN, RANK)\n",
    "\n",
    "            except FileNotFoundError: print(f\"Rank 0: Model checkpoint {MODEL_SAVE_PATH_MAIN} not found. Skipping final evaluation.\")\n",
    "            except Exception as e_eval: print(f\"Rank 0: Error during final model evaluation: {e_eval}\"); import traceback; traceback.print_exc()\n",
    "\n",
    "    # --- Cleanup DDP ---\n",
    "    if IS_DISTRIBUTED:\n",
    "        cleanup_distributed()\n",
    "\n",
    "    if RANK == 0:\n",
    "        print(\"Script finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
